<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mirsha A.K. - Portfolio</title>
    <!-- Bootstrap CSS -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <!-- Font Awesome -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
    <!-- Custom CSS -->
    <style>
        html {
            scroll-padding-top: 60px; /* Adjust this value to match your navbar height */
            scroll-behavior: smooth;

        }
        .profile-photo {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            object-fit: cover;
            border: 4px solid #fff;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .card {
            transition: transform 0.3s;
        }
        .card:hover {
            transform: scale(1.05);
            cursor: pointer;
        }
        .skills-container {
            display: flex;
            overflow-x: auto;
            padding-bottom: 10px;
            
        }
        .skills-container .card {
            flex: 0 0 auto;
            width: 300px;
            margin-right: 15px;
        }
        .modal-body img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin-bottom: 15px;
        }
        .modal-body pre {
            background: #f8f9fa;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
        }
        .navbar {
            background-color: #006aff !important;
            outline-color: white;
            box-shadow: 0 4px 6px #230665;
            position: fixed; /* Keeps the navbar fixed at the top */
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000; /* Ensures the navbar stays above other content */
        }
        /* Hero Section Gradient Animation */
        @keyframes gradientAnimation {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }

        header {
            background: linear-gradient(45deg, #230665, #2f0989, #4210b5, #2f0989, #230665);
            background-size: 300% 300%;
            animation: gradientAnimation 6s infinite alternate ease-in-out;
        }

    </style>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600&family=Montserrat:wght@700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>

    <!-- Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" style = "color:#006aff">
        <a class="navbar-brand" href="#" style="color: white;">Mirsha A.K.</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link" href="#about_me">About Me</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#projects">Projects</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#skills">Skills</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#certifications">Certificates</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#education">Education</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#reports">Reports Published</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#internship">Internship</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#contact">Contact</a>
                </li>
            </ul>
        </div>
    </nav>

    <!-- Hero Section -->
    <header class="bg-primary text-white text-center py-5">
        <div class="container">
            <img src="assets/Morningstar_face.jpg" alt="Mirsha A.K." class="profile-photo mb-3">
            <h1 class="display-4" style="color:white;">Mirsha A.K.</h1>
            <p class="lead">Full Stack Software Developer | Machine Learning & Deep Learning Engineer | MLOps & Data Science Developer</p>
            <a href="#contact" class="button_main btn btn-lg">Contact Me</a>

        </div>
    </header>

    <!-- Summary Section -->
    <section id="about_me" class="py-5">
        <div class="container">
            <h2 class="text-center mb-4">About Me</h2>
            <div class="row">
                <div class="col-md-12">
                    <div class="card mb-4 override_card">
                        <div class="card-body">
                            <h5 class="card-title">Full Stack Software Developer | Machine Learning & Deep Learning Engineer | MLOps & Data Science Developer</h5>
                            <p class="card-text">An Inspiring and Results-Oriented Full Stack Developer and AI Strategist with expertise in Data Science, Machine
                                 Learning Operations and Deep Learning. Adept at leveraging Python, SQL, and cutting-edge MLOPs techniques to
                                 drive intelligent, scalable solutions. Known for Strategic Problem-Solving, Visionary Thinking, and Collaborative
                                 Excellence, offering a unique blend of innovation and execution across data-driven and full stack projects.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Projects Section -->
    <section id="projects" class=" bg-dark py-6">
        <div class="container-fluid">
            <h2 class="text-center mb-4">Project Experience</h2>
            <p class="text-center text-muted" style="font-style: italic;">
            Click on any project card to view detailed project insights.
            </p>
            <br>
            <div class="row">
                <!-- Project 1 -->
                <div class="col-md-4">
                    <div class="card mb-4 project-card" data-toggle="modal" data-target="#project1Modal">
                        <div class="card-body project-body">
                            <h5 class="card-title">International GIS and Data Science Hackathon @ IIT Bombay</h5>
                            <p class="card-text">AI, IoT, Networking, QGIS, Mapping, Strategy Building</p>
                        </div>
                        <div class="hover-overlay">Click to view details</div>
                    </div>
                </div>
                <!-- Project 2 -->
                <div class="col-md-4">
                    <div class="card mb-4 project-card" data-toggle="modal" data-target="#project2Modal">
                        <div class="card-body project-body">
                            <h5 class="card-title">AgroNexum Live - Marketplace Management System</h5>
                            <p class="card-text">Flask, SQLAlchemy, MySQL, Python, HTML, CSS, Javascript, Bootstrap, Web Deployment</p>
                        </div>
                        <div class="hover-overlay">Click to view details</div>
                    </div>
                </div>
                <!-- Project 3 -->
                <div class="col-md-4">
                    <div class="card mb-4 project-card" data-toggle="modal" data-target="#project3Modal">
                        <div class="card-body project-body">
                            <h5 class="card-title">Interactive Dashboard Deployment via Streamlit</h5>
                            <p class="card-text">Python, ML, AI, Streamlit, Data Visualisation and Exploration, Matplotlib, Plotly</p>
                        </div>
                        <div class="hover-overlay">Click to view details</div>
                    </div>
                </div>
                <!-- Project 4 -->
                <div class="col-md-4">
                    <div class="card mb-4 project-card" data-toggle="modal" data-target="#project4Modal">
                        <div class="card-body project-body">
                            <h5 class="card-title">OS File System Control and Deadlock Management with Multithreading</h5>
                            <p class="card-text">Python, C++, Operating System Design Principles, Multi-Threading</p>
                        </div>
                        <div class="hover-overlay">Click to view details</div>
                    </div>
                </div>
                <!-- Project 5 -->
                <div class="col-md-4">
                    <div class="card mb-4 project-card" data-toggle="modal" data-target="#project5Modal">
                        <div class="card-body project-body">
                            <h5 class="card-title">GRAM SCHMIDT ORTHOGONALIZATION, SVD, LEAST SQUARE APPROXIMATION</h5>
                            <p class="card-text">Python, ML, AI, Optimisation Techniques, Math, Data Science</p>
                        </div>
                        <div class="hover-overlay">Click to view details</div>
                    </div>
                </div>
                <!-- Project 6 -->
                <div class="col-md-4">
                    <div class="card mb-4 project-card" data-toggle="modal" data-target="#project6Modal">
                        <div class="card-body project-body">
                            <h5 class="card-title">3D Point Cloud Analysis and Processing</h5>
                            <p class="card-text">Python, ML, AI, Graphs, LiDAR, Object Classification, Part Segmentation, Semantic Segmentation, Graph Neural Networks, Deep Learning, Data Visualisation and Exploration, Plotly</p>
                        </div>
                        <div class="hover-overlay">Click to view details</div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Project Modals -->
    <!-- Project 1 Modal -->
    <div class="modal fade" id="project1Modal" tabindex="-1" aria-labelledby="project1ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="project1ModalLabel">International GIS and Data Science Hackathon</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Technologies:</strong> AI, IoT, Networking, QGIS, Mapping, Strategy Building</p>
                    <p><strong>Project Github Repository: <a href="https://github.com/MirshaMorningstar/IIT-Bombay---Fossee-Mapathon-2023-Championship-ProjectWork">Project Link</a></strong></p>
                    <p><strong>Description:</strong> Led IIT Bombay FOSSEE Mapathon 2023, developed 4 AI-powered healthcare and safety maps for Nilgiris. Conducted Geospatial Data Collection, AIoT modeling, produced 3x more accurate maps which have a potential to improve 85% of the existing emergency response times and regional infrastructure planning in simulation.</p>
                    <img src="assets/project1-photo.png" alt="Project 1 Photo">
                </div>
                <div class="modal-body">
                    <h1 id="iit-bombay-fossee-mapathon-2023-demarcating-the-deadliest-roads-and-achieving-aiot-amelioration">IIT Bombay FOSSEE Mapathon 2023: Demarcating the Deadliest Roads and Achieving AIoT Amelioration</h1>
                    <h3 id="apr-2023-jun-2023">Apr 2023 - Jun 2023</h3>
                    <p>In the realm of academic pursuits, the &quot;IIT Bombay FOSSEE Mapathon 2023&quot; was a pivotal chapter in my academic journey. Hosted by the Indian Institute of Technology Bombay in collaboration with other esteemed organizations, this national-level competition brought together bright minds united by their passion for crafting cartographic creations.</p>
                    <p>Uniting enthusiasts of AI and data science, we set forth to create a comprehensive AI-powered map of healthcare and safety networks in the challenging Nilgiris region.</p>
                    <h2 id="project-overview-">Project Overview:</h2>
                    <p><img src="https://github.com/MirshaMorningstar/IIT-Bombay---Fossee-Mapathon-2023-Championship-ProjectWork/assets/84216040/754178af-3cbf-4f34-8d0c-d6e108582232" alt="The_Nilgiris_Map"></p>
                    <p><img src="https://github.com/MirshaMorningstar/IIT-Bombay---Fossee-Mapathon-2023-Championship-ProjectWork/assets/84216040/c195f8dd-8a44-4d68-8364-84e144c06e74" alt="The_Nilgiris_Landslide"></p>
                    <p><img src="https://github.com/MirshaMorningstar/IIT-Bombay---Fossee-Mapathon-2023-Championship-ProjectWork/assets/84216040/202e0396-145a-42fd-8525-d36e628dc889" alt="Inida_HNT_SpaceNet"></p>
                    <p><img src="https://github.com/MirshaMorningstar/IIT-Bombay---Fossee-Mapathon-2023-Championship-ProjectWork/assets/84216040/ebd2b1f5-5de7-4c89-bfd4-b181e8351135" alt="The_Nilgiris_AeroNet"></p>
                    <p>Our project, titled &quot;Demarcating the Deadliest Roads and Achieving AIoT Amelioration,&quot; involved meticulous geospatial data collection and the intricate task of modeling AIoT (Artificial Intelligence of Things) for data visualization. As the project lead, I oversaw over 80% of the work, grappling with complex technical challenges, making critical decisions, and ensuring that our project remained on course.</p>
                    <h2 id="achievements-and-insights">Achievements and Insights</h2>
                    <p>Our efforts yielded maps that provided actionable insights for improving the lives and infrastructure of the Nilgiris region. This experience reinforced the transformative potential of AI and data science, fueling my passion to explore their capabilities further.</p>
                    <p>This project was a testament to the boundless possibilities that emerge when technical excellence meets a sense of purpose. It reinforced my belief in the transformative power of AI and data science and ignited a passion to continue exploring their potential.</p>
                    <h2 id="reflections-and-future-directions">Reflections and Future Directions</h2>
                    <p>In retrospect, the &quot;IIT Bombay FOSSEE Mapathon 2023&quot; was more than a competition; it was a journey of exploration, collaboration, and innovation. It was a moment when the promise of AI and data science was brought to life, and the potential for transformation became palpable. It was a voyage that enriched my understanding of the power of technology to impact lives positively, and it remains an enduring source of inspiration as I continue to explore the vast landscape of AI and data science.</p>
                    <h2 id="ai-in-real-world-non-deterministic-domains">AI in Real-World Non-Deterministic Domains</h2>
                    <p>The project underscored the significance of deploying AI in real-world, non-deterministic domains. Non-deterministic environments, characterized by unpredictability and variability, present unique challenges and opportunities for AI applications. Here are key insights and planning strategies for AI in such domains:</p>
                    <h3 id="adaptive-algorithms">Adaptive Algorithms</h3>
                    <p>In non-deterministic environments, AI systems must be adaptive. Algorithms need to be designed to learn from real-time data and evolve based on new information. This adaptive approach allows AI to handle unexpected scenarios and make informed decisions under uncertainty.</p>
                    <h3 id="robust-data-collection">Robust Data Collection</h3>
                    <p>Accurate and comprehensive data collection is crucial. In our project, we utilized a combination of satellite imagery, drone surveys, and ground-based sensors to gather diverse geospatial data. This robust data foundation enabled our AI models to perform effectively even in the face of incomplete or noisy data.</p>
                    <h3 id="simulation-and-modeling">Simulation and Modeling</h3>
                    <p>Simulations play a vital role in planning AI strategies for non-deterministic domains. By creating virtual models of real-world environments, we can test AI algorithms under various conditions and refine them before deployment. In our project, simulations helped us predict traffic patterns, identify high-risk areas, and propose mitigation strategies.</p>
                    <h3 id="interdisciplinary-collaboration">Interdisciplinary Collaboration</h3>
                    <p>Addressing non-deterministic challenges requires interdisciplinary collaboration. Our team included experts in AI, geospatial analysis, civil engineering, and urban planning. This diverse expertise allowed us to approach problems from multiple angles and develop holistic solutions.</p>
                    <h3 id="continuous-monitoring-and-feedback">Continuous Monitoring and Feedback</h3>
                    <p>AI systems in non-deterministic domains must be continuously monitored and updated. Real-time feedback loops enable the system to learn from its performance and improve over time. In our project, ongoing monitoring of road conditions and traffic incidents provided valuable insights for iterative improvements.</p>
                    <h2 id="conclusion">Conclusion</h2>
                    <p>The &quot;IIT Bombay FOSSEE Mapathon 2023&quot; highlighted the potential of AI to navigate and transform complex, real-world environments. By leveraging adaptive algorithms, robust data collection, simulations, interdisciplinary collaboration, and continuous monitoring, we demonstrated the practical applications of AI in non-deterministic domains.</p>
                    <p>This journey not only advanced our technical skills but also deepened our understanding of AI&#39;s role in creating safer, more efficient, and resilient communities. As I continue to explore the vast landscape of AI and data science, this experience remains a guiding beacon, inspiring me to push the boundaries of what technology can achieve in the real world.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Project 2 Modal -->
    <div class="modal fade" id="project2Modal" tabindex="-1" aria-labelledby="project2ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="project2ModalLabel"> AgroNexum Live - Marketplace Management System</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Technologies:</strong> Flask, SQLAlchemy, MySQL, Python, HTML, CSS, Javascript, Bootstrap, Web Deployment</p>
                    <p><strong>Description:</strong> Designed and deployed a streamlined DBMS with advanced features like triggers, procedures, OTP login. Optimised data non-redundancy and process efficiency by about 30% for seamless agrarian-customer interactions.</p>
                    <p><strong>Project Link: <a href="https://mirsha.pythonanywhere.com/"> Live Link - Hosted Project </a></strong></p>
                    <img src="assets/project2-photo.png" alt="Project 2 Photo">
                    
                </div>

                <div class="modal-body">
                    <h1 id="dbms-mini-project-agronexumlive">DBMS - Mini Project: AgroNexumLive</h1>
                    <h2 id="grower-s-marketplace-management-system-agronexumlive">Grower&#39;s Marketplace Management System, AgroNexumLive</h2>
                    <p>Transforming agricultural landscapes, bringing together farmers, livestock experts, and consumers, our platform simplifies produce listings, delivering bespoke news and security with transparent transactions. Join our thriving, trusted community in cultivating a more connected and vibrant agricultural future.</p>
                    <h2 id="table-of-contents">Table of Contents</h2>
                    <ol>
                    <li><a href="#executive-summary">Executive Summary</a><ol>
                    <li><a href="#purpose">Purpose</a></li>
                    <li><a href="#target-users">Target Users</a></li>
                    <li><a href="#unique-value-proposition">Unique Value Proposition</a></li>
                    </ol>
                    </li>
                    <li><a href="#introduction">Introduction</a><ol>
                    <li><a href="#connecting-agriculture-to-consumers">Connecting Agriculture to Consumers</a></li>
                    <li><a href="#motivation-and-purpose">Motivation and Purpose</a></li>
                    <li><a href="#filling-the-market-void">Filling the Market Void</a></li>
                    <li><a href="#main-objectives">Main Objectives</a></li>
                    </ol>
                    </li>
                    <li><a href="#market-analysis">Market Analysis</a><ol>
                    <li><a href="#understanding-todays-agricultural-landscape">Understanding Today&#39;s Agricultural Landscape</a></li>
                    <li><a href="#addressing-the-disconnect">Addressing the Disconnect</a></li>
                    <li><a href="#evidencing-the-demand">Evidencing the Demand</a></li>
                    <li><a href="#filling-the-market-void-2">Filling the Market Void</a></li>
                    </ol>
                    </li>
                    <li><a href="#unique-selling-points">Unique Selling Points</a><ol>
                    <li><a href="#agrarian-centric-usps">Agrarian-Centric USPs</a></li>
                    <li><a href="#consumer-centric-usps">Consumer-Centric USPs</a></li>
                    </ol>
                    </li>
                    <li><a href="#technical-stack">Technical Stack</a><ol>
                    <li><a href="#backend-framework">Backend Framework</a></li>
                    <li><a href="#frontend-technologies">Frontend Technologies</a></li>
                    <li><a href="#database">Database</a></li>
                    <li><a href="#third-party-integrations">Third-Party Integrations</a></li>
                    </ol>
                    </li>
                    <li><a href="#software-requirements">Software Requirements</a></li>
                    <li><a href="#hardware-requirements">Hardware Requirements</a></li>
                    <li><a href="#features-and-functionality">Features and Functionality</a><ol>
                    <li><a href="#for-farmers">For Farmers</a></li>
                    <li><a href="#for-consumers">For Consumers</a></li>
                    <li><a href="#mobile-friendly-experience">Mobile-Friendly Experience</a></li>
                    <li><a href="#login-through-otp">Login through OTP</a></li>
                    </ol>
                    </li>
                    <li><a href="#user-experience">User Experience</a><ol>
                    <li><a href="#farmer-centric-experience">Farmer-Centric Experience</a></li>
                    <li><a href="#consumer-focused-design">Consumer-Focused Design</a></li>
                    </ol>
                    </li>
                    <li><a href="#contents-and-working-of-agronexumlive">Contents and Working of AgroNexumLive</a><ol>
                    <li><a href="#home-page">Home Page</a></li>
                    <li><a href="#user-entities">User Entities</a></li>
                    <li><a href="#sign-up-page">Sign Up Page</a></li>
                    <li><a href="#login-page">Login Page</a></li>
                    <li><a href="#agrarian-register-page">Agrarian Register Page</a></li>
                    <li><a href="#add-produce-type-page">Add Produce Type Page</a></li>
                    <li><a href="#agrarian-details-page">Agrarian Details Page</a></li>
                    <li><a href="#available-products-page">Available Products Page</a></li>
                    <li><a href="#communication-channel-for-agronexumlive">Communication Channel for AgroNexumLive</a></li>
                    </ol>
                    </li>
                    <li><a href="#database-2">Database</a><ol>
                    <li><a href="#modeling-language">Modeling Language</a></li>
                    <li><a href="#data-structures">Data Structures</a></li>
                    <li><a href="#query-language-and-report-writer">Query Language and Report Writer</a></li>
                    <li><a href="#data-security">Data Security</a></li>
                    <li><a href="#interactive-database-management">Interactive Database Management</a></li>
                    <li><a href="#transaction-mechanism-acid-properties">Transaction Mechanism (ACID Properties)</a></li>
                    <li><a href="#redundancy-avoidance">Redundancy Avoidance</a></li>
                    <li><a href="#adaptability-to-information-changes">Adaptability to Information Changes</a></li>
                    </ol>
                    </li>
                    <li><a href="#sql-structured-query-language">SQL (Structured Query Language)</a><ol>
                    <li><a href="#data-definition-ddl">Data Definition (DDL)</a></li>
                    <li><a href="#data-manipulation-dml">Data Manipulation (DML)</a></li>
                    <li><a href="#data-retrieval">Data Retrieval</a></li>
                    <li><a href="#data-filtering-and-sorting">Data Filtering and Sorting</a></li>
                    <li><a href="#data-aggregation">Data Aggregation</a></li>
                    <li><a href="#data-joins">Data Joins</a></li>
                    <li><a href="#data-integrity-enforcement">Data Integrity Enforcement</a></li>
                    <li><a href="#transactional-control">Transactional Control</a></li>
                    <li><a href="#index-management">Index Management</a></li>
                    <li><a href="#user-authorization-and-security">User Authorization and Security</a></li>
                    <li><a href="#stored-procedures-and-functions">Stored Procedures and Functions</a></li>
                    <li><a href="#views">Views</a></li>
                    <li><a href="#triggers">Triggers</a></li>
                    <li><a href="#data-backup-and-recovery">Data Backup and Recovery</a></li>
                    </ol>
                    </li>
                    <li><a href="#an-overview-of-our-database-design">An Overview of our Database Design</a><ol>
                    <li><a href="#tables">Tables</a></li>
                    <li><a href="#auto-increment-information">Auto-increment Information</a></li>
                    <li><a href="#index-information">Index Information</a></li>
                    <li><a href="#views-2">Views</a></li>
                    <li><a href="#functions">Functions</a></li>
                    <li><a href="#stored-procedures">Stored Procedures</a></li>
                    <li><a href="#triggers-2">Triggers</a></li>
                    <li><a href="#summary">Summary</a></li>
                    </ol>
                    </li>
                    <li><a href="#conceptual-er-diagram">Conceptual ER Diagram</a></li>
                    <li><a href="#schema-diagram">Schema Diagram</a></li>
                    <li><a href="#future-development-and-expansion">Future Development and Expansion</a><ol>
                    <li><a href="#scalability-and-technological-adaptability">Scalability and Technological Adaptability</a></li>
                    <li><a href="#enhanced-user-experience-and-features">Enhanced User Experience and Features</a></li>
                    <li><a href="#market-expansion-and-community-building">Market Expansion and Community Building</a></li>
                    <li><a href="#security-and-privacy-enhancements">Security and Privacy Enhancements</a></li>
                    </ol>
                    </li>
                    <li><a href="#conclusion">Conclusion</a></li>
                    </ol>
                    <h2 id="executive-summary">Executive Summary</h2>
                    <h3 id="purpose">Purpose</h3>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/e9346b3b-d50b-4a5e-8494-53891b387d01" alt="Screenshot (13)"></p>
                    <p>AgroNexumLive emerges as a pioneering platform designed to foster symbiotic relationships between growers, livestock luminaries, and consumers. Our primary objective is to revolutionize the agricultural landscape by integrating these crucial stakeholders, thereby enhancing efficiency and transparency across the supply chain.</p>
                    <h3 id="target-users">Target Users</h3>
                    <p>AgroNexumLive serves as the nexus where growers, livestock luminaries, and consumers converge, facilitating seamless interactions, knowledge sharing, and transactions. By leveraging technology, our platform aims to transcend barriers and bridge the gap between traditional farming practices and modern consumer demands.</p>
                    <h3 id="unique-value-proposition">Unique Value Proposition</h3>
                    <p>Our platform caters to a diverse audience encompassing farmers seeking innovative cultivation methods, livestock luminaries striving for industry insights, and discerning consumers eager for sustainable, quality agricultural products.</p>
                    <p>AgroNexumLive stands out through its holistic approach, offering a comprehensive suite of tools and resources. It empowers growers with data-driven insights, connects livestock luminaries with valuable market trends, and provides consumers access to ethically sourced, high-quality produce.</p>
                    <p>In essence, AgroNexumLive represents not just a platform but a transformative force driving agricultural evolution. It embodies collaboration, knowledge exchange, and a commitment to sustainability, positioning itself as a pivotal player in shaping the future of agriculture.</p>
                    <h2 id="introduction">Introduction</h2>
                    <h3 id="connecting-agriculture-to-consumers">Connecting Agriculture to Consumers</h3>
                    <p>AgroNexumLive, a visionary digital platform, serves as the dynamic bridge knitting together farmers, agrarians, and consumers in an interconnected ecosystem. Our venture stems from a profound motivation to address the longstanding gaps within the agricultural market, driven by the imperative need for cohesion and transparency across its diverse stakeholders.</p>
                    <h3 id="motivation-and-purpose">Motivation and Purpose</h3>
                    <p>At its core, AgroNexumLive redefines the agricultural landscape by propelling the convergence of farmers and consumers onto a unified platform. This synergy seeks to establish a direct, symbiotic relationship, eliminating intermediaries and fostering an environment where agricultural producers can directly engage with and serve the end consumers.</p>
                    <h3 id="filling-the-market-void">Filling the Market Void</h3>
                    <p>The genesis of AgroNexumLive arises from the recognition of fragmented interactions within the agricultural sector. Traditional models often obscure transparency and impede direct connections between growers and consumers. Our motivation is to dismantle these barriers, empowering farmers with broader market reach while providing consumers access to ethically sourced, farm-fresh produce.</p>
                    <h3 id="main-objectives">Main Objectives</h3>
                    <p>AgroNexumLive stands poised at the forefront of this transformative journey, pioneering a paradigm shift in agricultural interactions. By seamlessly interlinking agrarians and consumers, it strives to cultivate a more transparent, sustainable, and mutually beneficial agricultural ecosystem.</p>
                    <h2 id="market-analysis">Market Analysis</h2>
                    <h3 id="understanding-today-s-agricultural-landscape">Understanding Today&#39;s Agricultural Landscape</h3>
                    <p>Design and develop a user-friendly system for improved accessibility and ease of use.</p>
                    <h3 id="addressing-the-disconnect">Addressing the Disconnect</h3>
                    <p>Create an efficient computerized system that streamlines processes for enhanced productivity.</p>
                    <h3 id="evidencing-the-demand">Evidencing the Demand</h3>
                    <p>Develop an accurate and flexible system to eliminate data redundancy, ensuring data integrity.</p>
                    <h3 id="filling-the-market-void">Filling the Market Void</h3>
                    <p>Study the functioning of the Farm Management System for insights into agricultural processes.</p>
                    <h2 id="unique-selling-points">Unique Selling Points</h2>
                    <h3 id="agrarian-centric-usps">Agrarian-Centric USPs</h3>
                    <h4 id="efficient-listing-and-management">Efficient Listing and Management</h4>
                    <p>AgroNexumLive redefines the way agrarians showcase their produce. The platform offers a streamlined process, empowering farmers to efficiently list and manage their products. Simplified interfaces and tools allow for easy updates, ensuring their offerings are consistently up-to-date for consumers.</p>
                    <h4 id="networking-opportunities">Networking Opportunities</h4>
                    <p>Beyond a mere marketplace, AgroNexumLive functions as a digital ecosystem fostering connections among farmers. It serves as a nexus</p>
                    <p> where agrarians collaborate, exchange knowledge, and form partnerships. By facilitating these interactions, the platform enables a community-driven approach to agriculture, promoting innovation and best practices.</p>
                    <h4 id="customized-profiles">Customized Profiles</h4>
                    <p>Each agrarian on AgroNexumLive benefits from a comprehensive profile. These profiles serve as detailed showcases, highlighting not only their produce but also their expertise and practices. Through these personalized profiles, consumers gain insights into the journey of the products they purchase, fostering a deeper connection with the farmers.</p>
                    <h3 id="consumer-centric-usps">Consumer-Centric USPs</h3>
                    <h4 id="diverse-product-range">Diverse Product Range</h4>
                    <p>AgroNexumLive offers consumers an unparalleled variety of agricultural products sourced directly from verified growers. From fresh seasonal produce to artisanal goods, the platform provides access to a diverse and curated selection, ensuring consumers find exactly what they seek while discovering new, high-quality options.</p>
                    <h4 id="streamlined-communication">Streamlined Communication</h4>
                    <p>With the simplicity of a single click, consumers and buyers gain immediate access to the contact details of the farmer or grower. This user-friendly feature facilitates swift and direct communication, enhancing the overall convenience of connecting with agricultural producers. Whether inquiring about specific produce or establishing partnerships, this one-click accessibility ensures a seamless and efficient exchange between buyers and farmers, fostering a more connected and dynamic agricultural marketplace.</p>
                    <h2 id="technical-stack">Technical Stack</h2>
                    <h3 id="backend-framework">Backend Framework</h3>
                    <ul>
                    <li><strong>Python Flask</strong>
                    Employed as the primary backend framework, Flask provides a robust and flexible foundation for developing the application&#39;s server-side logic. Its lightweight nature and extensive libraries make it an ideal choice for building scalable web applications.</li>
                    </ul>
                    <h3 id="frontend-technologies">Frontend Technologies</h3>
                    <ul>
                    <li><p><strong>HTML, CSS, JavaScript (JS)</strong>
                    These fundamental web technologies form the core of the user interface. HTML structures the content, CSS styles the presentation, and JavaScript enables dynamic interactions and functionalities.</p>
                    </li>
                    <li><p><strong>Bootstrap</strong>
                    Leveraging the power of Bootstrap, a front-end framework, ensures a responsive and visually appealing design. Its grid system and pre-built components expedite the development process while maintaining consistency across different devices.</p>
                    </li>
                    </ul>
                    <h3 id="database">Database</h3>
                    <ul>
                    <li><strong>MySQL</strong>
                    Chosen as the database management system, MySQL efficiently stores and manages the application&#39;s data. Its reliability, speed, and scalability make it a popular choice for web-based applications.</li>
                    </ul>
                    <h3 id="third-party-integrations">Third-Party Integrations</h3>
                    <ul>
                    <li><strong>phpMyAdmin</strong>
                    Used as a graphical interface to manage MySQL databases, phpMyAdmin simplifies database operations such as querying, managing tables, and performing backups.</li>
                    </ul>
                    <h2 id="software-requirements">Software Requirements</h2>
                    <h3 id="frontend">Frontend</h3>
                    <ul>
                    <li><strong>HTML, CSS, JavaScript, Bootstrap</strong>
                    These technologies are used to build the user interface, ensuring a responsive and visually appealing design.</li>
                    </ul>
                    <h3 id="backend">Backend</h3>
                    <ul>
                    <li><strong>Python Flask (Python 3.7)</strong>
                    Flask is employed as the backend framework to develop the application&#39;s server-side logic.</li>
                    <li><strong>SQLAlchemy</strong>
                    Used for database management and interaction.</li>
                    </ul>
                    <h3 id="operating-system">Operating System</h3>
                    <ul>
                    <li><strong>Windows 10</strong>
                    The application is designed to run on the Windows 10 operating system.</li>
                    </ul>
                    <h3 id="web-browsers">Web Browsers</h3>
                    <ul>
                    <li><strong>Google Chrome / Internet Explorer</strong>
                    The application is compatible with these web browsers for optimal performance.</li>
                    </ul>
                    <h3 id="additional-software">Additional Software</h3>
                    <ul>
                    <li><strong>XAMPP (Version 3.7)</strong>
                    Used for setting up a local web server and managing the MySQL database.</li>
                    <li><strong>Python Main Editor (User Interface)</strong><ul>
                    <li><strong>PyCharm Community</strong>
                    PyCharm Community edition is used for developing and managing the Python codebase.</li>
                    </ul>
                    </li>
                    <li><strong>Workspace Editor</strong><ul>
                    <li><strong>Sublime Text 3</strong>
                    Sublime Text 3 is used as an additional code editor for convenience and flexibility.</li>
                    </ul>
                    </li>
                    </ul>
                    <hr>
                    <h2 id="hardware-requirements">Hardware Requirements</h2>
                    <ul>
                    <li><strong>Processor</strong><ul>
                    <li>Intel Core i5 or higher</li>
                    </ul>
                    </li>
                    <li><strong>RAM</strong><ul>
                    <li>Minimum 8 GB</li>
                    </ul>
                    </li>
                    <li><strong>Storage</strong><ul>
                    <li>Minimum 500 GB HDD or SSD</li>
                    </ul>
                    </li>
                    <li><strong>Display</strong><ul>
                    <li>1080p resolution monitor</li>
                    </ul>
                    </li>
                    <li><strong>Network</strong><ul>
                    <li>Stable internet connection for accessing external resources and updates</li>
                    </ul>
                    </li>
                    </ul>
                    <h2 id="features-and-functionality">Features and Functionality</h2>
                    <h3 id="for-farmers">For Farmers</h3>
                    <ol>
                    <li><p><strong>Efficient Listing System</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>HTML, CSS, JavaScript:</strong> Streamlined product listing process for user-friendly interfaces.</li>
                    <li><strong>MySQL:</strong> Database integration for managing and updating product information.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Customized Profile</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>HTML, CSS, Bootstrap:</strong> Detailed agrarian profiles to highlight expertise and produce specifics.</li>
                    <li><strong>Python Flask:</strong> Managing profile details and integrating with the database.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Inventory Management</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>PHP:</strong> Tools for tracking inventory and managing product availability.</li>
                    <li><strong>MySQL, phpMyAdmin:</strong> Integration for handling inventory data.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Product Showcase</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>Bootstrap:</strong> Creating visually appealing product displays and showcasing produce details.</li>
                    <li><strong>JavaScript:</strong> Interactive product displays and image galleries.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Password Encryption</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>PHP, Encryption Libraries:</strong> Implementing password encryption mechanisms for heightened security during the signup process.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="for-consumers">For Consumers</h3>
                    <ol>
                    <li><p><strong>Diverse Product Range</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>HTML, CSS, JavaScript:</strong> Displaying and categorizing a wide variety of agricultural products.</li>
                    <li><strong>Bootstrap:</strong> Responsive and visually engaging product presentation.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Secure Transaction</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>PHP:</strong> Implementing a secure payment gateway.</li>
                    <li><strong>MySQL:</strong> Database integration for handling transaction data securely.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Product Information</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>HTML, CSS, Bootstrap:</strong> Providing detailed information about products listed by farmers.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Search and Filtering</strong></p>
                    <ul>
                    <li><strong>Technology Used:</strong><ul>
                    <li><strong>JavaScript:</strong> Enabling users to search and filter products based on various criteria.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    </ol>
                    <hr>
                    <h2 id="contents-and-working-of-agronexumlive">Contents and Working of AgroNexumLive</h2>
                    <h3 id="home-page">Home Page</h3>
                    <ul>
                    <li><strong>Default Page:</strong> Home</li>
                    <li><strong>Features:</strong><ul>
                    <li>A visually appealing landing page to welcome users.</li>
                    <li>Navigation Links: Home, Agrarian Register, Add Produce Type, Agrarian Details, Records Created.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="user-entities">User Entities</h3>
                    <ol>
                    <li><p><strong>Admin</strong></p>
                    <ul>
                    <li>Full access to the web app.</li>
                    <li>Can view detailed records and available products.</li>
                    <li>Ability to edit agrarian details and add listings.</li>
                    </ul>
                    </li>
                    <li><p><strong>Farmer</strong></p>
                    <ul>
                    <li>Access to view personal agrarian details.</li>
                    <li>Capability to add detailed listings for agricultural products.</li>
                    <li>Flexibility to edit their own profile information.</li>
                    </ul>
                    </li>
                    <li><p><strong>Consumer</strong></p>
                    <ul>
                    <li>Limited access, allowing the viewing of available product listings.</li>
                    <li>Functionality to contact farmers for specific products.</li>
                    </ul>
                    </li>
                    <li><p><strong>Unlogged User</strong></p>
                    <ul>
                    <li>Basic access to view available products.</li>
                    <li>Required to sign up or log in for contacting farmers.</li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="sign-up-page">Sign Up Page</h3>
                    <ul>
                    <li><strong>Features:</strong><ul>
                    <li>Checkbox for identifying whether the user is a farmer or consumer.</li>
                    <li>Differential privileges granted based on the selected checkbox.</li>
                    <li>A personalized greeting email sent upon successful signup.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="login-page">Login Page</h3>
                    <ul>
                    <li><strong>Features:</strong><ul>
                    <li>Users input their email address and password for authentication.</li>
                    <li>A welcome-back email is dispatched after every successful login.</li>
                    <li>Option for OTP login in case of a forgotten password.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="agrarian-register-page">Agrarian Register Page</h3>
                    <ul>
                    <li><strong>Details Required:</strong><ul>
                    <li>Name</li>
                    <li>Aadhar number</li>
                    <li>Age</li>
                    <li>Gender</li>
                    <li>Contact number</li>
                    <li>Mail address (matching the signup details)</li>
                    <li>Registration for each type of produce they handle.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="add-produce-type-page">Add Produce Type Page</h3>
                    <ul>
                    <li><strong>Features:</strong><ul>
                    <li>Allows farmers to specify their agricultural focus.</li>
                    <li>Provides the ability to add custom product types.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="agrarian-details-page">Agrarian Details Page</h3>
                    <ul>
                    <li><strong>Features:</strong><ul>
                    <li>For Logged-In Agrarian:<ul>
                    <li>Comprehensive view of personal details.</li>
                    <li>Capability to add, edit, or delete product listings.</li>
                    <li>Options to edit or delete their profile.</li>
                    </ul>
                    </li>
                    <li>For Admin:<ul>
                    <li>Access to view all agrarian details.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="available-products-page">Available Products Page</h3>
                    <ul>
                    <li><strong>Features:</strong><ul>
                    <li>Products displayed in an aesthetically pleasing manner.</li>
                    <li>Listing order based on the time of insertion.</li>
                    <li>The &quot;Purchase&quot; button redirects to an email with the farmer&#39;s contact address for further communication.</li>
                    </ul>
                    </li>
                    </ul>
                    <hr>
                    <h2 id="communication-channels-for-agronexumlive">Communication Channels for AgroNexumLive</h2>
                    <h3 id="email-communication">Email Communication</h3>
                    <ul>
                    <li>An authentic email ID (agronexumlive@gmail.com) has been established for AgroNexumLive, facilitating official communication. This email is utilized for sending notifications, updates, and other relevant information to users.</li>
                    </ul>
                    <h3 id="whatsapp-groups">WhatsApp Groups</h3>
                    <ol>
                    <li><p><strong>AgroNexumLive Prospects&#39; Portal</strong></p>
                    <ul>
                    <li>A dedicated WhatsApp group for prospects and potential users of AgroNexumLive. This group serves as a platform for communication, inquiries, and discussions related to the application.</li>
                    </ul>
                    </li>
                    <li><p><strong>AgroNexumLive Agrarian&#39;s Portal</strong></p>
                    <ul>
                    <li>Another WhatsApp group specifically designed for agrarians associated with AgroNexumLive. This group fosters communication among farmers, allowing them to discuss, share experiences, and coordinate on agricultural matters.</li>
                    </ul>
                    </li>
                    <li><p><strong>Announcement Group</strong></p>
                    <ul>
                    <li>An announcement-focused WhatsApp group serves as a channel for posting updates, announcements, and important information regarding the AgroNexumLive application. This ensures that users stay informed about any developments or changes in the app.</li>
                    </ul>
                    </li>
                    </ol>
                    <h2 id="database">Database</h2>
                    <p>A Database Management System (DBMS) is specialized computer software designed to efficiently manage large sets of structured data and execute operations on the data as requested by multiple users. Prominent examples of DBMSs include Oracle, DB2, Microsoft Access, Microsoft SQL Server, Firebird, PostgreSQL, MySQL, SQLite, FileMaker, and Sybase Adaptive Server Enterprise. Database administrators commonly utilize DBMSs to create and maintain Database systems, with applications spanning areas such as accounting, human resources, and customer support systems.</p>
                    <p>DBMSs, once exclusive to large enterprises with the necessary hardware, have now become a standard component in the back-office operations of companies. The complexity of a DBMS lies in its comprehensive set of software programs that govern the organization, storage, management, and retrieval of data within a database. Key components of a DBMS include:</p>
                    <ul>
                    <li><p><strong>Schema Definition</strong>
                    Defines the schema of each database within the DBMS, adhering to the DBMS data model. The prevailing model, often embedded in SQL, is widely used despite criticisms from relational model purists.</p>
                    </li>
                    <li><p><strong>Optimized Structures</strong>
                    Optimized structures such as fields, records, files, and objects are designed to handle large datasets stored on permanent storage devices. Access to data in these structures may be relatively slower compared to volatile main memory.</p>
                    </li>
                    <li><p><strong>Database Query Language</strong>
                    Employs a database query language to interactively interrogate, analyze, and update the database. Supports user privileges on data, ensuring secure and controlled access.</p>
                    </li>
                    </ul>
                    <p>DBMSs also frequently support the Open Database Connectivity (ODBC) API, offering a standardized way for programmers to access the DBMS. This adaptability enhances practicality and performance, even though it may deviate from some fundamental relational model principles. The inclusion of a robust data query language and report writer allows users to interact with the database efficiently, facilitating analysis and updates in accordance with their data access privileges.</p>
                    <h3 id="key-features-of-a-dbms">Key Features of a DBMS</h3>
                    <ul>
                    <li><p><strong>Data Security</strong></p>
                    <ul>
                    <li>Prevents unauthorized users from accessing or modifying the database.</li>
                    <li>Access is controlled through passwords, with users having permission for the entire database or specific subsets known as sub-schemas.</li>
                    <li>Example: An employee database may contain all employee data, but certain users are restricted to viewing only payroll information, while others have access to work history and student data.</li>
                    </ul>
                    </li>
                    <li><p><strong>Interactive Database Management</strong></p>
                    <ul>
                    <li>If the DBMS supports interactive data entry, updates, and queries, it allows for managing personal databases.</li>
                    <li>However, lacking an audit trail or necessary controls, this capability might not be suitable for multi-user organizations.</li>
                    <li>Comprehensive controls are typically achieved through customized application programs for each data entry and updating function.</li>
                    </ul>
                    </li>
                    <li><p><strong>Transaction Mechanism (ACID Properties)</strong></p>
                    <ul>
                    <li>Ensures data integrity, even with concurrent user accesses (concurrency control) and faults (fault tolerance).</li>
                    <li>Maintains the integrity of the database by preventing multiple users from updating the same record simultaneously.</li>
                    <li>Unique index constraints, such as avoiding duplicate records, contribute to data integrity.</li>
                    </ul>
                    </li>
                    <li><p><strong>Redundancy Avoidance</strong></p>
                    <ul>
                    <li>The DBMS helps maintain database integrity by enforcing constraints, such as unique indexes, to prevent the entry of duplicate records.</li>
                    <li>For example, it ensures that no two customers with the same customer numbers (key fields) can be entered into the database.</li>
                    </ul>
                    </li>
                    <li><p><strong>Adaptability to Information Change</strong></p>
                    <ul>
                    <li>Organizations can easily adapt information systems to changing requirements with the use of a DBMS.</li>
                    <li>Different types of DBMS may be employed for daily transaction processing and analytical tasks, allowing for flexibility in system design.</li>
                    <li>Data administrators and systems analysts make overarching systems design decisions, while detailed database design is handled by database administrators.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="sql-structured-query-language-">SQL (Structured Query Language)</h3>
                    <p>Structured Query Language (SQL) serves as the primary language for manipulating relational databases, closely aligned with the relational model. In the relational model, data is organized into structures known as relations or tables. SQL statements are crafted for various purposes within the context of the Farm Management System:</p>
                    <ul>
                    <li><p><strong>Data Definition Language (DDL)</strong></p>
                    <ul>
                    <li>Involves defining tables and structures in the database.</li>
                    <li>DDL is used to create, alter, and drop schema objects such as tables and indexes.</li>
                    </ul>
                    </li>
                    <li><p><strong>Data Manipulation Language (DML)</strong></p>
                    <ul>
                    <li>Encompasses actions that interact with data within the tables.</li>
                    <li>Common DML operations include SELECT (retrieving data), INSERT (adding new records), UPDATE (modifying existing records), and DELETE (removing records).</li>
                    </ul>
                    </li>
                    <li><p><strong>Data Retrieval</strong></p>
                    <ul>
                    <li>SQL facilitates efficient data retrieval using SELECT statements, allowing users to query and retrieve specific information from the database.</li>
                    </ul>
                    </li>
                    <li><p><strong>Filtering and Sorting</strong></p>
                    <ul>
                    <li>SQL enables the application of filters and sorting criteria to refine query results.</li>
                    <li>WHERE clause filters data based on specified conditions, and ORDER BY clause sorts the results.</li>
                    </ul>
                    </li>
                    <li><p><strong>Aggregate Functions</strong></p>
                    <ul>
                    <li>SQL supports aggregate functions like SUM, AVG, COUNT, MIN, and MAX for summarizing and analyzing data across multiple records.</li>
                    </ul>
                    </li>
                    <li><p><strong>Join Operations</strong></p>
                    <ul>
                    <li>Enables the combination of data from multiple tables using JOIN operations.</li>
                    <li>Different types of joins, such as INNER JOIN and LEFT JOIN, allow for merging data based on specified relationships.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="additional-sql-features">Additional SQL Features</h3>
                    <ul>
                    <li><p><strong>Data Integrity Enforcement</strong></p>
                    <ul>
                    <li>SQL ensures data integrity through constraints like PRIMARY KEY, FOREIGN KEY, UNIQUE, and CHECK, maintaining the accuracy and consistency of the data.</li>
                    </ul>
                    </li>
                    <li><p><strong>Transactional Control</strong></p>
                    <ul>
                    <li>SQL includes commands like COMMIT and ROLLBACK to manage transactions, ensuring the integrity of the database during complex operations.</li>
                    </ul>
                    </li>
                    <li><p><strong>Index Management</strong></p>
                    <ul>
                    <li>Allows the creation and management of indexes to enhance query performance by providing faster access to specific data.</li>
                    </ul>
                    </li>
                    <li><p><strong>User Authorization and Security</strong></p>
                    <ul>
                    <li>SQL provides mechanisms for defining user roles, granting permissions, and enforcing security measures to control access to the database.</li>
                    </ul>
                    </li>
                    <li><p><strong>Stored Procedures and Functions</strong></p>
                    <ul>
                    <li>Supports the creation of stored procedures and functions, allowing the encapsulation of logic for reuse and efficiency.</li>
                    </ul>
                    </li>
                    <li><p><strong>Views</strong></p>
                    <ul>
                    <li>SQL allows the creation of views, which are virtual tables derived from the result of a SELECT query. Views simplify complex queries and provide an abstraction layer for users.</li>
                    </ul>
                    </li>
                    <li><p><strong>Triggers</strong></p>
                    <ul>
                    <li>Triggers in SQL are predefined actions that are automatically executed in response to specific events, such as INSERT, UPDATE, or DELETE operations. Triggers enhance data integrity and enforce business rules.</li>
                    </ul>
                    </li>
                    <li><p><strong>Data Backup and Recovery</strong></p>
                    <ul>
                    <li>SQL offers mechanisms for backing up and restoring databases, ensuring data resilience and recoverability in case of failures.</li>
                    </ul>
                    </li>
                    </ul>
                    <p>SQL, as the cornerstone of relational database management, empowers the Grower’s Marketplace Management System with a versatile set of tools for effective data manipulation, retrieval, and system management.</p>
                    <h3 id="an-overview-of-our-database-design">An Overview of Our Database Design</h3>
                    <h4 id="tables">Tables</h4>
                    <ol>
                    <li><p><strong>addagroproducts</strong></p>
                    <ul>
                    <li>Columns: 6 columns (username, email, pid, productname, productdesc, price)</li>
                    <li>Primary Key: pid</li>
                    <li>Auto-incremented: pid</li>
                    <li>Index: idx_username_addagroproducts on username</li>
                    </ul>
                    </li>
                    <li><p><strong>farming</strong></p>
                    <ul>
                    <li>Columns: 2 columns (fid, farmingtype)</li>
                    <li>Primary Key: fid</li>
                    <li>Auto-incremented: fid</li>
                    </ul>
                    </li>
                    <li><p><strong>register</strong></p>
                    <ul>
                    <li>Columns: 8 columns (rid, farmername, adharnumber, age, gender, phonenumber, address, farming)</li>
                    <li>Primary Key: rid</li>
                    <li>Auto-incremented: rid</li>
                    <li>Index: idx_adharnumber_register on adharnumber</li>
                    </ul>
                    </li>
                    <li><p><strong>test</strong></p>
                    <ul>
                    <li>Columns: 2 columns (id, name)</li>
                    <li>Primary Key: id</li>
                    <li>Auto-incremented: id</li>
                    </ul>
                    </li>
                    <li><p><strong>trig</strong></p>
                    <ul>
                    <li>Columns: 4 columns (id, fid, action, timestamp)</li>
                    <li>Primary Key: id</li>
                    <li>Auto-incremented: id</li>
                    <li>Index: idx_fid_trig on fid</li>
                    </ul>
                    </li>
                    <li><p><strong>user</strong></p>
                    <ul>
                    <li>Columns: 6 columns (id, username, email, password, is_agrarian, is_admin)</li>
                    <li>Primary Key: id</li>
                    <li>Auto-incremented: id</li>
                    </ul>
                    </li>
                    </ol>
                    <h4 id="auto-increment-information">Auto-increment Information</h4>
                    <ul>
                    <li>addagroproducts: pid is auto-incremented.</li>
                    <li>farming: fid is auto-incremented.</li>
                    <li>register: rid is auto-incremented.</li>
                    <li>test: id is auto-incremented.</li>
                    <li>trig: id is auto-incremented.</li>
                    <li>user: id is auto-incremented.</li>
                    </ul>
                    <h4 id="index-information">Index Information</h4>
                    <ul>
                    <li>addagroproducts: Index on username (idx_username_addagroproducts).</li>
                    <li>farming: No additional index mentioned.</li>
                    <li>register: Index on adharnumber (idx_adharnumber_register).</li>
                    <li>test: No additional index mentioned.</li>
                    <li>trig: Index on fid (idx_fid_trig).</li>
                    <li>user: No additional index mentioned.</li>
                    </ul>
                    <h4 id="views">Views</h4>
                    <ul>
                    <li><strong>addagroproducts_view</strong>: View for addagroproducts selecting columns pid, productname, productdesc, and price.</li>
                    <li><strong>register_view</strong>: View for register selecting columns farmername, adharnumber, phonenumber, and farming.</li>
                    </ul>
                    <h4 id="functions">Functions</h4>
                    <ul>
                    <li><strong>farming_count</strong>: Function that retrieves the total number of registered farmers for a given farming type.</li>
                    <li><strong>average_age_for_farming_type</strong>: Function that calculates the average age of farmers based on a given farming type.</li>
                    </ul>
                    <h4 id="stored-procedures">Stored Procedures</h4>
                    <ul>
                    <li><strong>calculate_total_value</strong>: Procedure that calculates and returns the total value of all products for a given user in addagroproducts.</li>
                    <li><strong>get_farmers_by_age_and_type</strong>: Procedure that retrieves the details of farmers who have a specified minimum age and are associated with a specific farming type.</li>
                    </ul>
                    <h4 id="triggers">Triggers</h4>
                    <ul>
                    <li><strong>Insertion Trigger</strong><ul>
                    <li>BEFORE DELETE ON register</li>
                    <li>Logs &quot;Agrarian DELETED&quot; with timestamp in trig.</li>
                    </ul>
                    </li>
                    <li><strong>Updation Trigger</strong><ul>
                    <li>AFTER INSERT ON register</li>
                    <li>Logs &quot;Agrarian Inserted&quot; with timestamp in trig.</li>
                    </ul>
                    </li>
                    <li><strong>After Update Trigger</strong><ul>
                    <li>AFTER UPDATE ON register</li>
                    <li>Logs &quot;</li>
                    </ul>
                    </li>
                    </ul>
                    <p>Agrarian UPDATED&quot; with timestamp in trig.</p>
                    <h3 id="summary">Summary</h3>
                    <ul>
                    <li><strong>Number of Tables:</strong> 6</li>
                    <li><strong>Number of Views:</strong> 2</li>
                    <li><strong>Number of Functions:</strong> 2</li>
                    <li><strong>Number of Stored Procedures:</strong> 2</li>
                    <li><strong>Number of Triggers:</strong> 3</li>
                    </ul>
                    <p>This comprehensive database design ensures robust data management, integrity, and security, tailored to the needs of the Grower’s Marketplace Management System.</p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/b5800104-e252-4765-b99b-3797e750a7d1" alt="image"></p>
                    <h2 id="future-development-and-expansion">Future Development and Expansion</h2>
                    <h3 id="scalability-and-technological-adaptability">Scalability and Technological Adaptability</h3>
                    <ol>
                    <li><p><strong>Scalable Infrastructure</strong></p>
                    <ul>
                    <li><strong>Cloud-Based Solutions</strong><ul>
                    <li>Consideration of cloud-based solutions (AWS, Azure) for enhanced scalability and performance.</li>
                    </ul>
                    </li>
                    <li><strong>Containerization</strong><ul>
                    <li>Integration of Docker containers for streamlined deployment and scaling based on demand.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Adoption of Advanced Frameworks</strong></p>
                    <ul>
                    <li><strong>Frontend Enhancements</strong><ul>
                    <li>Explore the integration of React.js or Vue.js for frontend enhancements, ensuring better interactivity and responsiveness.</li>
                    </ul>
                    </li>
                    <li><strong>Backend Transition</strong><ul>
                    <li>Consider transitioning backend functionalities to Node.js for a more unified JavaScript environment.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="enhanced-user-experience-and-features">Enhanced User Experience and Features</h3>
                    <ol>
                    <li><p><strong>Mobile Application Development</strong></p>
                    <ul>
                    <li><strong>Platform Expansion</strong><ul>
                    <li>Plan and develop mobile applications (iOS, Android) to expand market reach and cater to on-the-go users.</li>
                    </ul>
                    </li>
                    <li><strong>Feature Parity</strong><ul>
                    <li>Ensure feature parity with the web platform to maintain a consistent user experience across devices.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Real-time Analytics and Reporting</strong></p>
                    <ul>
                    <li><strong>Analytics Tools</strong><ul>
                    <li>Implement analytics tools (Google Analytics, custom dashboards) for data-driven insights.</li>
                    </ul>
                    </li>
                    <li><strong>Sales Reports</strong><ul>
                    <li>Provide agrarian users with detailed sales reports, aiding in decision-making and market analysis.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="market-expansion-and-community-building">Market Expansion and Community Building</h3>
                    <ol>
                    <li><p><strong>Regional Expansion</strong></p>
                    <ul>
                    <li><strong>Geographical Growth</strong><ul>
                    <li>Strategize market expansion to encompass different geographical regions or global markets.</li>
                    </ul>
                    </li>
                    <li><strong>Localization</strong><ul>
                    <li>Localize the platform by offering multi-language support to engage a wider user base.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Community Forums or Knowledge Hub</strong></p>
                    <ul>
                    <li><strong>Knowledge Sharing</strong><ul>
                    <li>Introduce a knowledge-sharing section for farmers, enabling discussions, tips, and best practices.</li>
                    </ul>
                    </li>
                    <li><strong>Community Engagement</strong><ul>
                    <li>Foster a sense of community by organizing webinars or virtual events centered around agricultural advancements.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="security-and-privacy-enhancements">Security and Privacy Enhancements</h3>
                    <ol>
                    <li><p><strong>Advanced Security Measures</strong></p>
                    <ul>
                    <li><strong>User Authentication</strong><ul>
                    <li>Implement additional layers of security protocols such as OAuth for user authentication and authorization.</li>
                    </ul>
                    </li>
                    <li><strong>Security Audits</strong><ul>
                    <li>Conduct regular security audits and updates to ensure robust protection against emerging threats.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    <li><p><strong>Privacy-Centric Features</strong></p>
                    <ul>
                    <li><strong>Privacy Controls</strong><ul>
                    <li>Offer granular privacy controls to farmers, enabling them to manage their data visibility.</li>
                    </ul>
                    </li>
                    <li><strong>Regulatory Compliance</strong><ul>
                    <li>Ensure compliance with data protection regulations (GDPR, CCPA) for consumer data handling.</li>
                    </ul>
                    </li>
                    </ul>
                    </li>
                    </ol>
                    <p>By focusing on these areas, the Grower’s Marketplace Management System can not only enhance its current offerings but also position itself for future growth and adaptation to changing technological landscapes and market needs.</p>
                    <h2 id="conclusion">Conclusion</h2>
                    <p>The trajectory of AgroNexumLive propels towards a future steeped in innovation and adaptability. Our roadmap aligns with the relentless pursuit of technological advancements, ensuring that our platform remains at the forefront of agricultural digitalization. We are committed to refining user experience, streamlining accessibility across devices, and fortifying our security infrastructure to uphold trust and reliability.</p>
                    <p>Our vision extends beyond the present, focusing on market expansion while catering to the evolving demands of farmers and consumers. We envisage AgroNexumLive not just as a solution but as a dynamic, scalable entity poised to revolutionize agricultural ecosystems. With a strategic blend of technological sophistication and user-centric design, we aspire to cement our position as the go-to platform in the ever-evolving agricultural landscape, offering unparalleled value and resilience.</p>
                    <h2 id="output">Output</h2>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/aec1f3e6-469c-4b40-bbbf-fabd2d4c8354" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/cab27b9a-ea6e-471a-8a7f-661b78d70e7d" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/7edb0fcb-6804-424b-9272-60b93689bf24" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/c3c12862-b8d4-4c34-87fe-de56b1f8eab3" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/71347530-e9e6-41b4-84c6-0047b3a5fa21" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/4cadb6db-14b8-42a1-ab6f-a05fb74850e9" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/588c407c-3fcf-4c9d-af99-f8a709442dea" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/a7b86445-cdd7-4143-8784-89893cfe07df" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/ff73266b-fae2-4961-a131-327fc6a26ed5" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/ef26ba61-6bfb-48f0-bb0e-49fb00ecd70b" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/e48bcd58-1fb2-4ba6-b726-7e38beea6a25" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/1fa550ba-db6c-4a3f-af6c-7d0ce3decdc2" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/e54667ae-4fd9-43fd-bf08-744b2200abc0" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/04da7e10-4f0e-4fca-9946-49fa837b42e4" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/7a760965-42be-4236-b810-b5054292a9a5" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/AgroNexumLive-DBMS-MiniProject/assets/84216040/852d3798-9657-4829-9b54-ba56d0a339f3" alt="image"></p>

                </div>
            </div>
        </div>
    </div>

    <!-- Project 3 Modal -->
    <div class="modal fade" id="project3Modal" tabindex="-1" aria-labelledby="project3ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="project3ModalLabel"> Interactive Dashboard Deployment via Streamlit</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Technologies:</strong> Python, ML, AI, Streamlit, Data Visualisation and Exploration, Matplotlib, Plotly</p>
                    <p><strong>Project Github Repository: <a href="https://github.com/MirshaMorningstar/US-Accidents-Dashboard">Project Link</a></strong></p>
                    <p><strong>Description:</strong> Developed a Dynamic Dashboard for data analysis, visualization, feature engineering, Hypothesis Testing, Hyperparameter Optimisation, boosting 20 ML models' accuracy to 98.7%, data processing efficiency by 30%.</p>
                    <img src="assets/project3-photo.png" alt="Project 3 Photo">
                </div>

                <div class="modal-body">
                    <h1>The US Accidents Analysis and Case Study Dashboard</h1>
                    <p>Welcome to the US Accidents Dashboard Project! This unique and comprehensive dashboard provides detailed insights into traffic accidents across the United States. Below is a detailed overview of the project, including its purpose, features, and requirements.</p>
                
                    <h2>Table of Contents</h2>
                    <ul>
                        <li><a href="#executive-summary">Executive Summary</a></li>
                        <li><a href="#introduction">Introduction</a></li>
                        <li><a href="#market-analysis">Market Analysis</a></li>
                        <li><a href="#unique-selling-points">Unique Selling Points (USPs)</a></li>
                        <li><a href="#dataset-description">Dataset Description</a></li>
                        <li><a href="#plots">Plots</a></li>
                        <li><a href="#hardware-requirements">Hardware Requirements</a></li>
                        <li><a href="#software-requirements">Software Requirements</a></li>
                        <li><a href="#conclusion">Conclusion</a></li>
                    </ul>
                
                    <h2 id="executive-summary">Executive Summary</h2>
                    <h3>Purpose</h3>
                    <p>The purpose of this project is to create an interactive and user-friendly web page to explore and visualize a US accident dataset (2016-2023). The dashboard aims to uncover key insights and patterns related to accidents, including their severity and the influence of various factors such as location, time, and weather conditions.</p>
                
                    <h3>Target Users</h3>
                    <p>The primary users of this dashboard include policymakers, researchers, traffic safety analysts, and the general public. These users can leverage the dashboard to understand accident trends, improve road safety measures, and make data-driven decisions.</p>
                
                    <h3>Unique Value Proposition</h3>
                    <p>This dashboard stands out by offering a comprehensive and intuitive platform for analyzing US accident data. It combines various features such as data quality visualization, feature engineering, preprocessing, and both general and inferential visualizations. These tools enable users to gain deeper insights into accident data, making it a valuable resource for improving traffic safety and informing policy decisions.</p>
                
                    <h2 id="introduction">Introduction</h2>
                    <h3>Connecting Our Dashboard to Users</h3>
                    <p>Our US Accidents Dashboard is designed to bridge the gap between complex data and user-friendly analysis. By offering an interactive and intuitive platform, we enable users to easily explore and understand accident data. We have deployed our project using Streamlit Cloud, making it easily accessible to users anytime, anywhere, without the need for complex installations or configurations.</p>
                
                    <h3>Motivation and Purpose</h3>
                    <p>The motivation behind this project is to leverage data to improve road safety. With thousands of accidents occurring every day, understanding the factors that contribute to these incidents is crucial. The purpose of this dashboard is to provide a tool that helps users identify trends, analyze patterns, and ultimately contribute to reducing accidents on the roads.</p>
                
                    <h3>Filling the Market Void</h3>
                    <p>Currently, there is a lack of accessible, comprehensive tools for analyzing US accident data. Many existing solutions are either too complex for the average user or too simplistic to provide meaningful insights. Our dashboard fills this void by combining ease of use with powerful analytical capabilities, offering a unique solution that meets the needs of a wide range of users.</p>
                
                    <h3>Main Objectives</h3>
                    <p>The main objectives of our dashboard are:</p>
                    <ul>
                        <li>To provide an interactive platform for exploring US accident data.</li>
                        <li>To visualize data quality, including missing values and outliers.</li>
                        <li>To prepare data for exploration by normalizing, binning, and sampling.</li>
                        <li>To enable detailed analysis of accident factors such as location, time, and weather.</li>
                        <li>To filter the data for analysis.</li>
                        <li>To support feature engineering and data preprocessing for deeper insights.</li>
                        <li>To offer both general and inferential visualizations to help users draw meaningful conclusions from the data.</li>
                        <li>To develop visually appealing and informative data visualizations.</li>
                        <li>To design and evaluate color palettes for visualization based on principles of perception, enhancing readability and interpretability.</li>
                    </ul>
                
                    <h2 id="market-analysis">Market Analysis</h2>
                    <h3>Market Demand</h3>
                    <p>The demand for data-driven insights in the transportation and safety sector is at an all-time high. As cities grow and the number of vehicles on the road increases, there is a pressing need for tools that can help analyze and mitigate traffic accidents. Governments, city planners, and safety organizations are seeking advanced solutions to improve road safety and reduce accident rates. This demand creates a significant opportunity for our US Accidents Dashboard. Our dashboard stands out in the market as a versatile, user-friendly, and comprehensive tool for traffic accident analysis, meeting the needs of a broad spectrum of users from policymakers to the general public.</p>
                
                    <h2 id="unique-selling-points">Unique Selling Points (USPs)</h2>
                    <h3>Streamlined Accessibility</h3>
                    <p>Our project offers easy access to complex data analysis tools through deployment on Streamlit Cloud. Users can access the dashboard from anywhere with an internet connection, eliminating the need for software installations or technical setups.</p>
                
                    <h3>Comprehensive Analysis Features</h3>
                    <p>Unlike many existing solutions, our dashboard provides a comprehensive suite of analysis tools. From data quality assessment to feature engineering and inferential visualizations, users can perform a wide range of analyses without switching between multiple platforms.</p>
                
                    <h3>Intuitive User Interface</h3>
                    <p>With Streamlit's user-friendly interface, users of all technical backgrounds can navigate the dashboard effortlessly. Clear visualizations and interactive controls make data exploration and interpretation straightforward and engaging.</p>
                
                    <h3>Cost-Effective Solution</h3>
                    <p>Built on open-source technology and deployed on Streamlit Cloud, our project offers a cost-effective alternative to expensive proprietary software. Users can access powerful analysis capabilities without the prohibitive costs associated with professional-grade tools.</p>
                
                    <h3>Real-Time Data Analysis</h3>
                    <p>By leveraging Streamlit Cloud's capabilities, our dashboard can analyze and visualize real-time data updates. This feature ensures that users always have access to the most up-to-date insights, allowing for timely decision-making and response to changing conditions.</p>
                
                    <h3>Customizable Visualizations</h3>
                    <p>Users can tailor the visualizations to their specific needs and preferences. With options to change color palettes, adjust plot sizes, and select specific data subsets, users can create customized views that highlight the insights most relevant to their objectives.</p>
                
                    <h3>Educational Value</h3>
                    <p>Beyond its analytical capabilities, our project serves as an educational tool for understanding traffic accident data. Users can learn about data quality assessment, preprocessing techniques, and inferential analysis methods through interactive exploration of real-world datasets.</p>
                
                    <h3>Community Support and Collaboration</h3>
                    <p>As part of the Streamlit ecosystem, our project benefits from a vibrant community of users and developers. Users can share insights, collaborate on analysis projects, and contribute to the ongoing development and improvement of the dashboard.</p>
                
                    <h2 id="dataset-description">Dataset Description</h2>
                    <p><strong>Dataset:</strong> US-Accidents: A Countrywide Traffic Accident Dataset</p>
                    <p>This is a countrywide traffic accident dataset, which covers 49 states of the United States. The data is continuously being collected from February 2016 - 2023, using several data providers, including multiple APIs that provide streaming traffic event data. These APIs broadcast traffic events captured by a variety of entities, such as the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road-networks. Currently, there are about 0.5 million accident records in this dataset. Check the below descriptions for more detailed information.</p>
                
                    <h3>A Detailed Breakthrough</h3>
                    <p><strong>Dataset Source:</strong> The dataset is sourced from [relevant source, e.g., Kaggle].</p>
                    <p><strong>Data Structure:</strong> The dataset includes 46 columns, each providing different details about the accidents. Key columns include:</p>
                    <ul>
                        <li><strong>ID:</strong> This is a unique identifier of the accident record.</li>
                        <li><strong>Severity:</strong> Shows the severity of the accident, a number between 1 and 4, where 1 indicates the least impact on traffic (i.e., short delay as a result of the accident) and 4 indicates a significant impact on traffic (i.e., long delay).</li>
                        <li><strong>Start_Time:</strong> Shows start time of the accident in the local time zone.</li>
                        <li><strong>End_Time:</strong> Shows end time of the accident in the local time zone. End time here refers to when the impact of an accident on traffic flow was dismissed.</li>
                        <li><strong>Start_Lat:</strong> Shows latitude in GPS coordinate of the start point.</li>
                        <li><strong>Start_Lng:</strong> Shows longitude in GPS coordinate of the start point.</li>
                        <li><strong>End_Lat:</strong> Shows latitude in GPS coordinate of the end point.</li>
                        <li><strong>End_Lng:</strong> Shows longitude in GPS coordinate of the end point.</li>
                        <li><strong>Distance(mi):</strong> The length of the road extent affected by the accident.</li>
                        <li><strong>Description:</strong> Shows natural language description of the accident.</li>
                        <li><strong>Number:</strong> Shows the street number in the address field.</li>
                        <li><strong>Street:</strong> Shows the street name in the address field.</li>
                        <li><strong>City:</strong> Shows the city in the address field.</li>
                        <li><strong>County:</strong> Shows the county in the address field.</li>
                        <li><strong>State:</strong> Shows the state in the address field.</li>
                        <li><strong>ZipCode:</strong> Shows the zip code in the address field.</li>
                        <li><strong>Country:</strong> Shows the country in the address field.</li>
                        <li><strong>Timezone:</strong> Shows timezone based on the location of the accident (eastern, central, etc.).</li>
                        <li><strong>Airport_Code:</strong> Denotes an airport-based weather station which is the closest one to location of the accident.</li>
                        <li><strong>Weather_Timestamp:</strong> Shows the time-stamp of a weather observation record (in local time).</li>
                        <li><strong>Temperature(F):</strong> Shows the temperature (in Fahrenheit).</li>
                        <li><strong>Wind_Chill(F):</strong> Shows the wind chill (in Fahrenheit).</li>
                        <li><strong>Humidity(%):</strong> Shows the humidity (in percentage).</li>
                        <li><strong>Pressure(in):</strong> Shows the air pressure (in inches).</li>
                        <li><strong>Visibility(mi):</strong> Shows visibility (in miles).</li>
                        <li><strong>Wind_Direction:</strong> Shows wind direction.</li>
                        <li><strong>Wind_Speed(mph):</strong> Shows wind speed (in miles per hour).</li>
                        <li><strong>Precipitation(in):</strong> Shows precipitation amount in inches, if there is any.</li>
                        <li><strong>Weather_Condition:</strong> Shows the weather condition (rain, snow, thunderstorm, fog, etc.)</li>
                        <li><strong>Amenity:</strong> A POI annotation which indicates presence of amenity in a nearby location.</li>
                        <li><strong>Bump:</strong> A POI annotation which indicates presence of speed bump or hump in a nearby location.</li>
                        <li><strong>Crossing:</strong> A POI annotation which indicates presence of crossing in a nearby location.</li>
                        <li><strong>Give_Way:</strong> A POI annotation which indicates presence of give_way in a nearby location.</li>
                        <li><strong>Junction:</strong> A POI annotation which indicates the presence of a junction in a nearby location.</li>
                        <li><strong>No_Exit:</strong> A POI annotation which indicates presence of no_exit in a nearby location.</li>
                        <li><strong>Railway:</strong> A POI annotation which indicates presence of railway in a nearby location.</li>
                        <li><strong>Roundabout:</strong> A POI annotation which indicates the presence of a roundabout in a nearby location.</li>
                        <li><strong>Station:</strong> A POI annotation which indicates presence of a station in a nearby location.</li>
                        <li><strong>Stop:</strong> A POI annotation which indicates presence of stop in a nearby location.</li>
                        <li><strong>Traffic_Calming:</strong> A POI annotation which indicates presence of traffic_calming in a nearby location.</li>
                        <li><strong>Traffic_Signal:</strong> A POI annotation which indicates presence of traffic_signal in a nearby location.</li>
                        <li><strong>Turning_Loop:</strong> A POI annotation which indicates presence of turning_loop in a nearby location.</li>
                        <li><strong>Sunrise_Sunset:</strong> Shows the period of day (i.e. day or night) based on sunrise/sunset.</li>
                        <li><strong>Civil_Twilight:</strong> Shows the period of day (i.e. day or night) based on civil twilight.</li>
                        <li><strong>Nautical_Twilight:</strong> Shows the period of day (i.e. day or night) based on nautical twilight.</li>
                        <li><strong>Astronomical_Twilight:</strong> Shows the period of day (i.e. day or night) based on astronomical twilight.</li>
                        <li><strong>Year:</strong> The year component extracted from the Start_Time attribute.</li>
                        <li><strong>Month:</strong> The month component extracted from the Start_Time attribute.</li>
                        <li><strong>Day:</strong> The day component extracted from the Start_Time attribute.</li>
                        <li><strong>Hour:</strong> The hour component extracted from the Start_Time attribute.</li>
                        <li><strong>Minute:</strong> The minute component extracted from the Start_Time attribute.</li>
                        <li><strong>Second:</strong> The second component extracted from the Start_Time attribute.</li>
                        <li><strong>Hour_Category:</strong> A categorical attribute that categorizes the accidents based on the hour of the day (e.g., morning, afternoon, evening, night).</li>
                    </ul>
                
                    <h2 id="plots">Plots</h2>
                    <ul>
                        <li><strong>Heatmap for Missing Values:</strong> A heatmap visually represents missing data in a dataset, highlighting the presence and pattern of missing values across different features.</li>
                        <li><strong>Pie Chart:</strong> A pie chart displays data as slices of a circle, showing the relative proportions of different categories within a dataset.</li>
                        <li><strong>Bar Plot:</strong> A bar plot uses rectangular bars to represent and compare the frequency or value of different categories.</li>
                        <li><strong>Violin Plot for Outlier:</strong> A violin plot combines a box plot with a kernel density plot, showing the distribution, probability density, and presence of outliers in the data.</li>
                        <li><strong>Box Plot for Outliers:</strong> A box plot summarizes the distribution of a dataset, highlighting the median, quartiles, and potential outliers through the use of "whiskers" and individual points.</li>
                        <li><strong>Histogram for Data Distribution:</strong> A histogram displays the frequency distribution of a dataset by grouping data into bins and showing the count of data points in each bin.</li>
                        <li><strong>Quantile-Quantile Plot for Normalization Visualization:</strong> A quantile-quantile (Q-Q) plot compares the quantiles of a dataset to the quantiles of a theoretical distribution, helping to assess if the data follows the desired distribution, such as normality.</li>
                        <li><strong>Bar Plot for Binning:</strong> A bar plot for binning groups continuous data into discrete bins and represents the count or frequency of data points in each bin.</li>
                        <li><strong>Scatter Plot:</strong> A scatter plot displays individual data points on a two-dimensional plane, showing the relationship between two numerical variables.</li>
                        <li><strong>Line Plot:</strong> A line plot connects data points with lines, typically used to show trends over time or the relationship between two continuous variables.</li>
                        <li><strong>Rose Plot:</strong> A rose plot (circular bar plot or wind rose) displays data in circular segments, often used to represent cyclic data like wind direction and speed.</li>
                        <li><strong>Folium Map to Visualize US Accident Places:</strong> A Folium map uses the Folium library to create interactive maps, plotting locations of accidents across the United States for geographical analysis.</li>
                    </ul>
                
                    <h3 id="hardware-requirements">Hardware Requirements</h3>
                    <p><strong>Development Machine</strong></p>
                    <ul>
                    <li><strong>Processor</strong>: Intel Core i3 or equivalent</li>
                    <li><strong>RAM</strong>: 8 GB or more</li>
                    <li><strong>Storage</strong>: 256 GB SSD or more</li>
                    <li><strong>Operating System</strong>: Windows 10, macOS, or Linux</li>
                    </ul>
                    <p><strong>Server (if self-hosting instead of using Streamlit Cloud)</strong></p>
                    <ul>
                    <li><strong>Processor</strong>: Intel Xeon or equivalent</li>
                    <li><strong>RAM</strong>: 16 GB or more</li>
                    <li><strong>Storage</strong>: 500 GB SSD or more</li>
                    <li><strong>Operating System</strong>: Linux (Ubuntu 20.04 LTS or later recommended)</li>
                    <li><strong>Network</strong>: High-speed internet connection with at least 10 Mbps upload/download speed</li>
                    </ul>
                    <h3 id="software-requirements">Software Requirements</h3>
                    <p><strong>Programming Language</strong></p>
                    <ul>
                    <li><strong>Python</strong>: Version 3.8 or higher</li>
                    </ul>
                    <p><strong>Python Libraries</strong></p>
                    <ul>
                    <li><strong>Streamlit</strong>: For building and deploying the dashboard</li>
                    <li><strong>pandas</strong>: For data manipulation and analysis</li>
                    <li><strong>Plotly</strong>: For interactive visualizations</li>
                    <li><strong>seaborn</strong>: For statistical data visualization</li>
                    <li><strong>numpy</strong>: For numerical operations</li>
                    <li><strong>scikit-learn</strong>: For machine learning and preprocessing tasks</li>
                    <li><strong>matplotlib</strong>: For basic plotting</li>
                    <li><strong>base58</strong>: A library for binary-to-text encoding, commonly used for creating short, human-readable identifiers.</li>
                    <li><strong>pillow</strong>: A Python Imaging Library (PIL) fork that adds image processing capabilities.</li>
                    <li><strong>lazypredict</strong>: A module that helps in building a lot of basic models without much code and helps understand which models work better without much parameter tuning.</li>
                    <li><strong>xgboost</strong>: An optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable.</li>
                    <li><strong>lightgbm</strong>: A highly efficient gradient boosting framework that uses tree-based learning algorithms.</li>
                    <li><strong>pytest</strong>: A testing framework for Python that makes it easy to write simple and scalable test cases.</li>
                    <li><strong>tqdm</strong>: A library providing fast, extensible progress bars for loops and other iterative tasks.</li>
                    <li><strong>ydata-profiling</strong>: A library that generates profile reports from a pandas DataFrame to understand data quickly.</li>
                    <li><strong>streamlit-pandas-profiling</strong>: An integration of Streamlit with pandas-profiling, allowing easy display of profile reports in a Streamlit app.</li>
                    <li><strong>Jinja2</strong>: A templating engine for Python, used for rendering templates to generate HTML or other markup languages.</li>
                    </ul>
                    <p><strong>Development Environment</strong></p>
                    <ul>
                    <li><strong>IDE/Code Editor</strong>: Visual Studio Code, Jupyter Notebook</li>
                    </ul>
                    <p><strong>Deployment Platform</strong></p>
                    <ul>
                    <li><strong>Streamlit Cloud</strong>: For hosting the dashboard online</li>
                    </ul>

                    <h3 id="conclusion">Conclusion</h3>
                    <p>This project has successfully developed an interactive and user-friendly web page for exploring and visualizing a comprehensive US accident dataset. Through the deployment on Streamlit Cloud, we have ensured that our dashboard is accessible from anywhere, without the need for complex installations, making it a versatile tool for a wide range of users, including policymakers, researchers, traffic safety analysts, and the general public.</p>
                    <p>This project has effectively filled a market void by providing a comprehensive, user-friendly, and cost-effective solution for analyzing US accident data. By transforming complex data into actionable intelligence through thoughtful design and robust analytical capabilities, our dashboard empowers users to make data-driven decisions, ultimately contributing to improved road safety and more informed policy decisions.</p>


                </div>
            </div>
        </div>
    </div>

    <!-- Project 4 Modal -->
    <div class="modal fade" id="project4Modal" tabindex="-1" aria-labelledby="project4ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="project4ModalLabel"> OS File System Control and Deadlock Management with Multithreading </h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Technologies:</strong> Python, C++, Operating System Design Principles, Multi-Threading</p>
                    <p><strong>Project Github Repository: <a href="https://github.com/MirshaMorningstar/OS_MiniProject">Project Link</a></strong></p>
                    <p><strong>Description:</strong> The first part of this project addresses the crucial challenge of managing file systems efficiently by implementing a comprehensive set of functionalities for manipulation and maintenance. It encompasses tasks such as file creation, viewing, modification, size retrieval, details extraction, clearing, and deletion. The second part of the project tackles the critical challenge of ensuring system reliability and stability in multithreading environments through the implementation of robust deadlock recovery mechanisms. It covers strategies such as deadlock detection using algorithms like Banker's algorithm, emphasizing controlled resource allocation to prevent deadlocks.
                    </p>
                    <img src="assets/os.png" alt="Project 4 Photo">
                </div>

                <div class="modal-body">
                    <h1 id="os-file-system-control-and-deadlock-management-with-multithreading">OS File System Control and Deadlock Management with Multithreading</h1>
                    <h2 id="project-overview">Project Overview</h2>
                    <p>This project focuses on two critical aspects of operating systems: efficient file system management and robust deadlock recovery mechanisms in multithreaded environments.</p>
                    <h3 id="part-1-file-system-management-tool">Part 1: File System Management Tool</h3>
                    <p>The first part of this project addresses the crucial challenge of managing file systems efficiently by implementing a comprehensive set of functionalities for manipulation and maintenance. It encompasses tasks such as file creation, viewing, modification, size retrieval, details extraction, clearing, and deletion.</p>
                    <h4 id="objectives">Objectives</h4>
                    <ul>
                    <li><strong>File Manipulation</strong>: Implement functionalities for creating, viewing, modifying, and deleting files to facilitate efficient file manipulation.</li>
                    <li><strong>File Details</strong>: Provide features to obtain essential file details such as size, creation date, and modification date to aid in file analysis.</li>
                    <li><strong>File Clearing</strong>: Offer mechanisms for clearing file content to maintain data privacy and security.</li>
                    <li><strong>User Interaction</strong>: Ensure user interaction through an intuitive menu-driven interface for easy navigation and operation.</li>
                    <li><strong>System Optimization</strong>: Leverage system resources and programming constructs to optimize file management tasks and enhance overall system reliability.</li>
                    </ul>
                    <h3 id="part-2-deadlock-management-in-multithreaded-environments">Part 2: Deadlock Management in Multithreaded Environments</h3>
                    <p>The second part of the project tackles the critical challenge of ensuring system reliability and stability in multithreading environments through the implementation of robust deadlock recovery mechanisms. It covers strategies such as deadlock detection using algorithms like Banker&#39;s algorithm, emphasizing controlled resource allocation to prevent deadlocks.</p>
                    <h4 id="objectives">Objectives</h4>
                    <ul>
                    <li><strong>Deadlock Detection</strong>: Implement a deadlock detection algorithm to periodically check for deadlock occurrences and identify the threads involved.</li>
                    <li><strong>Resource Allocation</strong>: Ensure consistent and controlled resource allocation to prevent deadlock situations. Utilize techniques such as resource hierarchies, request protocols, and preemption.</li>
                    <li><strong>Recovery Mechanisms</strong>: Develop a recovery mechanism to resolve deadlock scenarios, including preempting resources from threads or rolling back thread states.</li>
                    <li><strong>Thread Synchronization</strong>: Employ synchronization primitives like mutexes, semaphores, and condition variables to coordinate resource access among multiple threads effectively.</li>
                    <li><strong>Testing and Validation</strong>: Conduct extensive testing to validate the correctness and effectiveness of the deadlock recovery mechanisms. Test the system under various scenarios and edge cases to ensure robustness and reliability.</li>
                    </ul>
                    <h2 id="scope">Scope</h2>
                    <h3 id="file-system-management-tool">File System Management Tool</h3>
                    <ol>
                    <li><strong>File Manipulation</strong>: <ul>
                    <li>Design and implement functionalities for creating, viewing, modifying, and deleting files to facilitate efficient file manipulation.</li>
                    <li>Develop mechanisms for users to interact with files through an intuitive menu-driven interface.</li>
                    </ul>
                    </li>
                    <li><strong>File Details Extraction</strong>: <ul>
                    <li>Implement features to obtain essential file details such as size, creation date, and modification date to provide users with comprehensive file information.</li>
                    </ul>
                    </li>
                    <li><strong>File Clearing</strong>: <ul>
                    <li>Provide a mechanism for clearing file content to enable users to maintain data privacy and security by securely erasing file contents.</li>
                    </ul>
                    </li>
                    <li><strong>Error Handling and User Feedback</strong>: <ul>
                    <li>Incorporate robust error handling mechanisms to handle file operation failures gracefully and provide informative error messages to users.</li>
                    <li>Ensure clear and concise user feedback throughout the file manipulation process to enhance user experience and usability.</li>
                    </ul>
                    </li>
                    <li><strong>System Resource Optimization</strong>: <ul>
                    <li>Leverage system resources efficiently to optimize file management tasks and enhance overall system performance.</li>
                    <li>Implement mechanisms to minimize resource consumption and maximize system responsiveness during file operations.</li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="deadlock-management">Deadlock Management</h3>
                    <ol>
                    <li><strong>Deadlock Detection</strong>: <ul>
                    <li>Design and implement a deadlock detection algorithm to periodically check for deadlock occurrences in the system.</li>
                    <li>Develop mechanisms to identify the threads involved in deadlock situations.</li>
                    </ul>
                    </li>
                    <li><strong>Resource Allocation</strong>: <ul>
                    <li>Implement resource allocation methods to ensure resources are allocated in a consistent and controlled manner.</li>
                    <li>Explore techniques such as resource hierarchies, request protocols, and preemption to avoid deadlock situations.</li>
                    </ul>
                    </li>
                    <li><strong>Recovery Mechanism</strong>: <ul>
                    <li>Design and implement a robust recovery mechanism to resolve deadlock scenarios effectively.</li>
                    <li>Develop algorithms to preempt resources from threads or roll back thread states to mitigate deadlocks.</li>
                    </ul>
                    </li>
                    <li><strong>Thread Synchronization</strong>: <ul>
                    <li>Utilize synchronization primitives such as mutexes, semaphores, and condition variables to coordinate resource access among multiple threads.</li>
                    <li>Ensure threads acquire and release resources in a synchronized manner to prevent deadlock situations.</li>
                    </ul>
                    </li>
                    <li><strong>Testing and Validation</strong>: <ul>
                    <li>Conduct extensive testing to validate the correctness and effectiveness of the deadlock recovery mechanisms.</li>
                    <li>Test the system under various scenarios and edge cases to ensure robustness and reliability.</li>
                    </ul>
                    </li>
                    </ol>
                    <h2 id="limitations">Limitations</h2>
                    <h3 id="file-management-tool">File Management Tool</h3>
                    <ol>
                    <li><strong>Interface</strong>: <ul>
                    <li>Operates only on files with a terminal/shell-like interface. No sophisticated graphical user interfaces involved.</li>
                    </ul>
                    </li>
                    <li><strong>Security</strong>: <ul>
                    <li>File security features like authentication and password-protected encryption are not included in this mini-project.</li>
                    </ul>
                    </li>
                    <li><strong>Offline Mode</strong>: <ul>
                    <li>All file operations are considered functional only in offline mode and non-operational online.</li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="deadlock-recovery-and-management-tool">Deadlock Recovery and Management Tool</h3>
                    <ol>
                    <li><strong>Thread and Resource Limits</strong>: <ul>
                    <li>The deadlock avoidance, prevention, and recovery module is implemented with a maximum of 5 threads and 3 resources for simplicity and accuracy.</li>
                    </ul>
                    </li>
                    <li><strong>Real-World Applications</strong>: <ul>
                    <li>More complicated recovery mechanisms and tools need to be deployed for real-world deadlock challenges.</li>
                    </ul>
                    </li>
                    <li><strong>Banker’s Algorithm</strong>: <ul>
                    <li>Suitable only for processes and threads with static resource/memory requirements.</li>
                    </ul>
                    </li>
                    </ol>
                    <h2 id="algorithms">Algorithms</h2>
                    <h3 id="file-management-system">File Management System</h3>
                    <p><img src="https://github.com/MirshaMorningstar/OS_MiniProject/assets/84216040/d1aa790d-4701-400e-a669-24f997e6959f" alt="image"></p>
                    <h4 id="file-creation-and-management-algorithm">File Creation and Management Algorithm</h4>
                    <ol>
                    <li><strong>Initialization</strong>: <ul>
                    <li>Initialize constants and variables for file management operations.</li>
                    <li>Set up a mutex for thread synchronization to ensure concurrent file operations are executed safely.</li>
                    </ul>
                    </li>
                    <li><strong>File Creation</strong>: <ul>
                    <li>Implement functionality to create a new file and initialize it with user-provided content.</li>
                    <li>Handle errors gracefully if file creation fails due to permission issues or other system constraints.</li>
                    </ul>
                    </li>
                    <li><strong>File Viewing</strong>: <ul>
                    <li>Develop mechanisms to allow users to view the contents of an existing file.</li>
                    <li>Ensure proper error handling if the file specified by the user cannot be opened or does not exist.</li>
                    </ul>
                    </li>
                    <li><strong>File Modification</strong>: <ul>
                    <li>Implement functionality for users to modify the content of an existing file.</li>
                    <li>Ensure that the original content of the file is replaced entirely with the new content provided by the user.</li>
                    </ul>
                    </li>
                    <li><strong>File Deletion</strong>: <ul>
                    <li>Provide options for users to delete unwanted files from the system.</li>
                    <li>Handle file deletion operations carefully to prevent accidental data loss and confirm user intent before proceeding.</li>
                    </ul>
                    </li>
                    </ol>
                    <h4 id="file-information-retrieval-algorithm">File Information Retrieval Algorithm</h4>
                    <p><img src="https://github.com/MirshaMorningstar/OS_MiniProject/assets/84216040/5f69c565-c08d-48d2-b0d5-32bfb47cc33f" alt="image"></p>
                    <ol>
                    <li><strong>Obtain File Size</strong>: <ul>
                    <li>Develop mechanisms to retrieve the size of a specified file in bytes.</li>
                    <li>Utilize appropriate system calls or library functions to accurately determine the size of the file.</li>
                    </ul>
                    </li>
                    <li><strong>Retrieve File Details</strong>: <ul>
                    <li>Implement functionality to extract additional details about a file, such as its creation date, modification date, and other metadata.</li>
                    <li>Ensure that the retrieved file details are presented to the user in a clear and understandable format.</li>
                    </ul>
                    </li>
                    </ol>
                    <h4 id="error-handling-and-user-interaction">Error Handling and User Interaction</h4>
                    <ol>
                    <li><strong>Error Handling</strong>: <ul>
                    <li>Implement robust error handling mechanisms to handle various exceptional scenarios, such as file not found, permission denied, or insufficient disk space.</li>
                    </ul>
                    </li>
                    <li><strong>User Feedback</strong>: <ul>
                    <li>Provide informative feedback to users regarding the outcome of file management operations, including success messages or error notifications.</li>
                    </ul>
                    </li>
                    <li><strong>User Interface</strong>: <ul>
                    <li>Design the user interface to be intuitive and user-friendly, guiding users through the file management process seamlessly.</li>
                    </ul>
                    </li>
                    </ol>
                    <h3 id="deadlock-management-using-multithreading">Deadlock Management using Multithreading</h3>
                    <p><img src="https://github.com/MirshaMorningstar/OS_MiniProject/assets/84216040/82b8cbbc-c793-4d0d-bb50-9676d59a9041" alt="image"></p>
                    <h4 id="deadlock-detection-and-avoidance-using-banker-s-algorithm">Deadlock Detection and Avoidance using Banker’s Algorithm</h4>
                    <ol>
                    <li><strong>Initialization</strong>: <ul>
                    <li>Initialize constants NUM_RESOURCES and NUM_PROCESSES.</li>
                    <li>Initialize vectors available, maximum, allocation, need, and resourceGranted for resource management.</li>
                    <li>Acquire a mutex for thread synchronization.</li>
                    </ul>
                    </li>
                    </ol>
                    <p><img src="https://github.com/MirshaMorningstar/OS_MiniProject/assets/84216040/71063576-df31-42ed-a633-037f6205bc30" alt="image"></p>
                    <ol>
                    <li><strong>Resource Management</strong>: <ul>
                    <li>Implement isSafe function to check if a process can proceed safely.</li>
                    <li>Implement releaseResources function to release resources held by a process.</li>
                    <li>Implement requestResources function to request resources for a process, ensuring deadlock prevention and recovery.</li>
                    <li>Develop processThread function to simulate resource allocation and deallocation for each process in a separate thread.</li>
                    </ul>
                    </li>
                    </ol>
                    <p><img src="https://github.com/MirshaMorningstar/OS_MiniProject/assets/84216040/ceea44ce-c492-4396-83b5-91be46042d66" alt="image"></p>
                    <ol>
                    <li><strong>Main Execution</strong>: <ul>
                    <li>Prompt the user to input available instances of resources.</li>
                    <li>Prompt the user to input maximum instances of resources for each process.</li>
                    <li>Initialize threads for each process using processThread function.</li>
                    <li>Join all threads to synchronize their execution.</li>
                    </ul>
                    </li>
                    </ol>
                    <h4 id="deadlock-recovery-algorithm">Deadlock Recovery Algorithm</h4>
                    <p><img src="https://github.com/MirshaMorningstar/OS_MiniProject/assets/84216040/8691d13f-da34-48b3-b96b-e6a67558ed0f" alt="image"></p>
                    <ol>
                    <li><strong>Initialization</strong>: <ul>
                    <li>Define constants NUM_THREADS, NUM_RESOURCES, MAX_SLEEP, and MAX_ITERATIONS.</li>
                    <li>Implement the ResourceManager class to manage resources, including a mutex, condition variable, and vector to track resource availability.</li>
                    <li>Initialize a random number generator for deadlock recovery.</li>
                    </ul>
                    </li>
                    <li><strong>Resource Management</strong>: <ul>
                    <li>Implement requestResource method in the ResourceManager class to request resources for a thread, ensuring mutual exclusion.</li>
                    <li>Implement releaseResource method in the ResourceManager class to release acquired resources, notifying waiting threads.</li>
                    <li>Develop recoverFromDeadlock method in the ResourceManager class to preempt resources in case of deadlock detection.</li>
                    </ul>
                    </li>
                    <li><strong>Thread Execution</strong>: <ul>
                    <li>Implement threadFunction to simulate resource acquisition and release by each thread.</li>
                    <li>Inside threadFunction, loop until reaching the maximum iterations.</li>
                    <li>Request resources using requestResource, simulate critical section execution, and release resources.</li>
                    <li>Detect deadlock and initiate recovery mechanism using recoverFromDeadlock if necessary.</li>
                    </ul>
                    </li>
                    <li><strong>Main Execution</strong>: <ul>
                    <li>Initialize the random number generator.</li>
                    <li>Create instances of the ResourceManager class.</li>
                    <li>Create threads, each executing the threadFunction with a unique thread ID and reference to the ResourceManager.</li>
                    <li>Join all threads to synchronize their execution and ensure proper termination.</li>
                    </ul>
                    </li>
                    </ol>
                    <h4 id="deadlock-prevention-using-semaphores-mutex-condition-variable-multiple-threads">Deadlock Prevention Using Semaphores, Mutex, Condition Variable, Multiple Threads</h4>
                    <p><img src="https://github.com/MirshaMorningstar/OS_MiniProject/assets/84216040/7e4e9b9c-80e9-41df-ad82-5d20233f154c" alt="image"></p>
                    <ol>
                    <li><strong>Initialization</strong>:<ul>
                    <li>Define constants NUM_THREADS, NUM_RESOURCES, and MAX_SLEEP.</li>
                    <li>Implement the Semaphore class with methods wait and notify to control resource access.</li>
                    <li>Implement the ResourceManager class to manage resource acquisition and release.</li>
                    </ul>
                    </li>
                    <li><strong>Resource Acquisition and Release</strong>: <ul>
                    <li>Implement acquireResource method in the ResourceManager class to acquire resources, ensuring mutual exclusion.</li>
                    <li>Implement releaseResource method in the ResourceManager class to release acquired resources.</li>
                    </ul>
                    </li>
                    <li><strong>Thread Execution</strong>: <ul>
                    <li>Implement threadFunction to simulate resource acquisition and release by each thread.</li>
                    <li>Inside threadFunction, loop indefinitely.</li>
                    <li>Wait for a resource to become available using the Semaphore object&#39;s wait method.</li>
                    <li>Acquire a resource from the ResourceManager.</li>
                    <li>Perform some work, simulating critical section execution.</li>
                    <li>Release the acquired resource using the releaseResource method of the ResourceManager.</li>
                    <li>Notify the Semaphore object that a resource is available using the notify method.</li>
                    </ul>
                    </li>
                    <li><strong>Main Execution</strong>: <ul>
                    <li>Seed the random number generator.</li>
                    <li>Create instances of the ResourceManager and Semaphore classes.</li>
                    <li>Create threads, each executing the threadFunction with a unique thread ID.</li>
                    <li>Detach threads to allow them to run independently.</li>
                    <li>Sleep the main thread to allow child threads to execute.</li>
                    <li>Terminate the program after the specified duration.</li>
                    </ul>
                    </li>
                    </ol>
                    <p>By following these algorithms and implementing the specified functionalities, the project aims to enhance the reliability and stability of multithreaded systems while providing efficient file management tools and robust deadlock recovery solutions.</p>
                    


                </div>
            </div>
        </div>
    </div>

    <!-- Project 5 Modal -->
    <div class="modal fade" id="project5Modal" tabindex="-1" aria-labelledby="project5ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="project5ModalLabel"> GRAM SCHMIDT ORTHOGONALIZATION, SVD, LEAST SQUARE APPROXIMATION</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Technologies:</strong> Python, ML, AI, Optimisation Techniques, Math, Data Science</p>
                    <p><strong>Project Github Repository: <a href="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation">Project Link</a></strong></p>
                    <p><strong>Description:</strong> Developed a Dynamic Image Compression and Feature Extraction system using Artificial Intelligence - Optimisation algorithms such as Gram Schmidt Orthogonalisation and Least Squares Approximation and compressed image upto 85% with a minimum data quality loss of 5%.</p>
                    <img src="assets/gram-schmidt.png" alt="Project 3 Photo">
                </div>

                <div class="modal-body">
                    <h1 id="gram-schmidt-orthogonalization-svd-least-square-approximation">GRAM SCHMIDT ORTHOGONALIZATION, SVD, LEAST SQUARE APPROXIMATION</h1>
                    <h2 id="gram-schmidt-orthogonalization-based-feature-selection">Gram-Schmidt Orthogonalization Based Feature Selection</h2>
                    <h3 id="introduction-specificities-">Introduction Specificities:</h3>
                    <p>Gram-Schmidt Orthogonalization (GSO) is a mathematical technique used in feature selection to create a new set of features that are uncorrelated (orthogonal) to each other while capturing most of the information from the original features. This helps improve machine learning model performance and reduces computational cost by dealing with a smaller, more informative feature set.</p>
                    <h3 id="the-basic-concept-overview-">The Basic Concept Overview:</h3>
                    <p>Imagine you have a bunch of arrows (features) pointing in different directions. Feature selection with GSO aims to find a new set of arrows that represent the same space but are perpendicular (orthogonal) to each other. These new, uncorrelated features will capture the essential information from the originals without redundancy.</p>
                    <h3 id="the-process-flow-">The Process Flow:</h3>
                    <p>Here&#39;s the process:</p>
                    <ol>
                    <li>Start with the first original feature vector.</li>
                    <li>Project all subsequent features onto the space spanned by the already chosen features and remove that projection. This ensures the new feature is independent of the previous ones.</li>
                    <li>Normalize the remaining vector to get a unit-length new feature.</li>
                    <li>Repeat steps 2 and 3 for all remaining features.</li>
                    </ol>
                    <p>By the end, you have a set of orthogonal features that effectively capture the important information from the originals.</p>
                    <h3 id="mathematical-overview">Mathematical Overview</h3>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/dacdcfad-cac2-41cb-9333-374beeafd33c" alt="image"></p>
                    <p>Let&#39;s represent your original features as a set of vectors x_1, x_2, ..., x_n in an n-dimensional space. Here are the relevant formulas involved in GSO for feature selection:</p>
                    <p><strong>1. Projection:</strong> The projection of vector x_i onto the space spanned by</p>
                    <p>vectors x<em>1, ..., x</em>(j-1) is:
                    proj_(x<em>1, ..., x</em>(j-1)) (x_i) = ((x_i . x_1) / ||x_1||^2) <em> x_1 + ... + ((x<em>i . x</em>(j-1)) / ||x_(j-1)||^2) </em> x_(j-1)</p>
                    <p>where . denotes the dot product and ||x|| represents the vector&#39;s magnitude.</p>
                    <p><strong>2. Removing the projection:</strong> To get the part of x_i orthogonal to the existing features:</p>
                    <p>x_i&#39; = x<em>i - proj</em>(x<em>1, ..., x</em>(j-1)) (x_i)</p>
                    <p><strong>3. Normalization (optional):</strong> Normalize x_i&#39; to get a unit-length vector (useful for some algorithms):</p>
                    <p>x_j = x_i&#39; / ||x_i&#39; ||</p>
                    <p>Here, x_j represents the new, j-th orthogonal feature vector.</p>
                    <p>By iteratively applying these equations, you obtain a set of orthogonal feature
                    vectors that can be used in your machine learning model.</p>
                    <h3 id="breast-cancer-wisconsin-diagnostic-data-set">Breast Cancer Wisconsin (Diagnostic) Data Set</h3>
                    <h4 id="about-dataset-">About Dataset:</h4>
                    <p>The UCI Breast Cancer Wisconsin (Diagnostic) Dataset is a well-known dataset used for machine learning and statistical modeling, particularly for binary classification tasks.</p>
                    <h4 id="overview-">Overview:</h4>
                    <ul>
                    <li>Dataset Name: Breast Cancer Wisconsin (Diagnostic)</li>
                    <li>Source: UCI Machine Learning Repository</li>
                    <li>Number of Instances: 569</li>
                    <li>Number of Attributes: 30 numerical features (plus 1 target variable)</li>
                    <li>Task: Classification (Benign vs. Malignant)</li>
                    </ul>
                    <h4 id="attributes-information-">Attributes Information:</h4>
                    <p>The dataset consists of features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. The features are divided into three main categories: mean, standard error, and worst (largest) value. For each cell nucleus, the following features are provided:</p>
                    <ul>
                    <li>radius (mean of distances from center to points on the perimeter)</li>
                    <li>texture (standard deviation of gray-scale values)</li>
                    <li>perimeter</li>
                    <li>area</li>
                    <li>smoothness (local variation in radius lengths)</li>
                    <li>compactness (perimeter^2 / area - 1.0)</li>
                    <li>concavity (severity of concave portions of the contour)</li>
                    <li>concave points (number of concave portions of the contour)</li>
                    <li>symmetry</li>
                    <li>fractal dimension (&quot;coastline approximation&quot; - 1)</li>
                    </ul>
                    <h3 id="pythonic-code-">Pythonic Code:</h3>
                    <h4 id="step-1-load-and-preprocess-the-dataset">Step 1: Load and preprocess the dataset</h4>
                    <p>First, we&#39;ll load the Breast Cancer dataset and select 15 features.</p>
                    <pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
                    <span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
                    <span class="hljs-title">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_breast_cancer
                    <span class="hljs-title">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler
                    <span class="hljs-title">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
                    <span class="hljs-title">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> AdaBoostClassifier
                    <span class="hljs-title">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score
                    <span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
                    <span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns

                    <span class="hljs-meta"># Load the Breast Cancer dataset</span>
                    <span class="hljs-class"><span class="hljs-keyword">data</span> = load_breast_cancer()</span>
                    <span class="hljs-type">X</span> = <span class="hljs-class"><span class="hljs-keyword">data</span>.<span class="hljs-keyword">data</span></span>
                    <span class="hljs-title">y</span> = <span class="hljs-class"><span class="hljs-keyword">data</span>.target</span>

                    <span class="hljs-meta"># Select 15 features</span>
                    <span class="hljs-title">selected_features</span> = <span class="hljs-class"><span class="hljs-keyword">data</span>.feature_names[:15]</span>
                    <span class="hljs-type">X_selected</span> = <span class="hljs-type">X</span>[:, :<span class="hljs-number">15</span>]

                    <span class="hljs-meta"># Normalize the features</span>
                    <span class="hljs-title">scaler</span> = <span class="hljs-type">StandardScaler</span>()
                    <span class="hljs-type">X_normalized</span> = scaler.fit_transform(<span class="hljs-type">X_selected</span>)

                    <span class="hljs-meta"># Convert to DataFrame for better visualization</span>
                    <span class="hljs-title">df</span> = pd.<span class="hljs-type">DataFrame</span>(<span class="hljs-type">X_normalized</span>, columns=selected_features)
                    <span class="hljs-title">df</span>['target'] = y
                    <span class="hljs-title">print</span>(df.head())
                    </code></pre>
                    <h4 id="step-2-perform-gram-schmidt-orthogonalization">Step 2: Perform Gram-Schmidt Orthogonalization</h4>
                    <p>Next, we implement the Gram-Schmidt process to orthogonalize the feature vectors.</p>
                    <pre><code class="lang-python">def gram_schmidt(X):
                        Q = <span class="hljs-built_in">np</span>.zeros_like(X)
                        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(X.shape[<span class="hljs-number">1</span>]):
                            qi = X[:, i]
                            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i):
                                qj = Q[:, j]
                                qi -= <span class="hljs-built_in">np</span>.dot(qi, qj) * qj
                            qi /= <span class="hljs-built_in">np</span>.linalg.norm(qi)
                            Q[:, i] = qi
                        <span class="hljs-built_in">return</span> Q

                    # Apply Gram-Schmidt process
                    Q = gram_schmidt(X_normalized)

                    # Convert to DataFrame <span class="hljs-keyword">for</span> visualization
                    df_orthogonal = pd.DataFrame(Q, <span class="hljs-built_in">columns</span>=selected_features)
                    df_orthogonal['target'] = y
                    <span class="hljs-built_in">print</span>(df_orthogonal.head())
                    </code></pre>
                    <h4 id="step-3-measure-orthogonality">Step 3: Measure Orthogonality</h4>
                    <p>We measure the orthogonality of the transformed features.</p>
                    <pre><code class="lang-python">def measure_orthogonality(Q):
                        orthogonality_matrix = <span class="hljs-built_in">np</span>.dot(Q.T, Q)
                        off_diagonal_elements = orthogonality_matrix - <span class="hljs-built_in">np</span>.<span class="hljs-built_in">diag</span>(<span class="hljs-built_in">np</span>.diagonal(orthogonality_matrix))
                        orthogonality_score = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">np</span>.<span class="hljs-built_in">abs</span>(off_diagonal_elements))
                        <span class="hljs-built_in">return</span> orthogonality_score

                    # Measure orthogonality
                    orthogonality_score = measure_orthogonality(Q)
                    <span class="hljs-built_in">print</span>(f'Orthogonality Score: {orthogonality_score}')
                    </code></pre>
                    <h4 id="step-4-evaluate-the-selected-features">Step 4: Evaluate the Selected Features</h4>
                    <p>We use a classifier to evaluate the performance of the selected features.</p>
                    <pre><code class="lang-python"><span class="hljs-comment"># Split the dataset</span>
                    X_train, X_test, y_train, <span class="hljs-attr">y_test</span> = train_test_split(Q, y, <span class="hljs-attr">test_size=0.1,</span> <span class="hljs-attr">random_state=42)</span>

                    <span class="hljs-comment"># Train a Logistic Regression classifier</span>
                    <span class="hljs-attr">clf</span> = AdaBoostClassifier(<span class="hljs-attr">n_estimators=1000,</span> <span class="hljs-attr">random_state=0)</span>
                    clf.fit(X_train, y_train)

                    <span class="hljs-comment"># Predict and evaluate</span>
                    <span class="hljs-attr">y_pred</span> = clf.predict(X_test)
                    <span class="hljs-attr">accuracy</span> = accuracy_score(y_test, y_pred)
                    print(f'Accuracy <span class="hljs-keyword">with</span> Orthogonalized Features: {accuracy}')
                    </code></pre>
                    <h4 id="step-5-generate-relevant-plots">Step 5: Generate Relevant Plots</h4>
                    <p>We will generate three plots:</p>
                    <ul>
                    <li>Correlation Matrix of Original Features</li>
                    <li>Correlation Matrix of Orthogonalized Features</li>
                    <li>Comparison of Model Performance with Original vs Orthogonalized Features.</li>
                    </ul>
                    <pre><code class="lang-python"><span class="hljs-comment"># Plot 1: Correlation Matrix of Original Features</span>
                    plt.figure(<span class="hljs-attr">figsize=(10,</span> <span class="hljs-number">8</span>))
                    sns.heatmap(df[selected_features].corr(), <span class="hljs-attr">annot=True,</span> <span class="hljs-attr">cmap='coolwarm',</span> <span class="hljs-attr">fmt='.2f')</span>
                    plt.title('Correlation Matrix of Original Features')
                    plt.show()

                    <span class="hljs-comment"># Plot 2: Correlation Matrix of Orthogonalized Features</span>
                    plt.figure(<span class="hljs-attr">figsize=(10,</span> <span class="hljs-number">8</span>))
                    sns.heatmap(df_orthogonal[selected_features].corr(), <span class="hljs-attr">annot=True,</span> <span class="hljs-attr">cmap='coolwarm',</span> <span class="hljs-attr">fmt='.2f')</span>
                    plt.title('Correlation Matrix of Orthogonalized Features')
                    plt.show()

                    <span class="hljs-comment"># Plot 3: Model Performance Comparison</span>
                    <span class="hljs-comment"># Evaluate the model on original features</span>
                    X_train_orig, X_test_orig, y_train_orig, <span class="hljs-attr">y_test_orig</span> = train_test_split(X_normalized, y, <span class="hljs-attr">test_size=0.3,</span> <span class="hljs-attr">random_state=42)</span>
                    <span class="hljs-attr">clf_orig</span> = LogisticRegression(<span class="hljs-attr">max_iter=10000)</span>
                    clf_orig.fit(X_train_orig, y_train_orig)
                    <span class="hljs-attr">y_pred_orig</span> = clf_orig.predict(X_test_orig)
                    <span class="hljs-attr">accuracy_orig</span> = accuracy_score(y_test_orig, y_pred_orig)

                    <span class="hljs-comment"># Bar plot comparison</span>
                    <span class="hljs-attr">accuracy_data</span> = pd.DataFrame({
                        'Features': ['Original', 'Orthogonalized'],
                        'Accuracy': [accuracy_orig, accuracy]
                    })
                    plt.figure(<span class="hljs-attr">figsize=(8,</span> <span class="hljs-number">6</span>))
                    sns.barplot(<span class="hljs-attr">x='Features',</span> <span class="hljs-attr">y='Accuracy',</span> <span class="hljs-attr">data=accuracy_data)</span>
                    plt.title('Model Performance Comparison')
                    plt.ylim(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)
                    plt.show()
                    </code></pre>
                    <h3 id="outputs-generated">Outputs Generated</h3>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/91f01233-1c61-4f95-ab13-4b53fbfb439f" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/2c4ca692-eabf-49ea-b40b-5e76178ade62" alt="image"></p>
                    <h4 id="inference-">Inference:</h4>
                    <p>Therefore, we can notice that after the orthogonalization of the considered dataset and performing Classification on the selected &quot;Top K&quot; Attributes of the resultant dataset, there has been a drastic improvement in the Accuracy Performance of the Classification Model from a mere 0.68 to a much appreciated 0.93 %. This strengthens our knowledge on the effects of orthogonal transformation on the data.</p>
                    <h2 id="svd-and-least-square-approximation">SVD and Least Square Approximation</h2>
                    <h3 id="introduction-specificities-">Introduction Specificities:</h3>
                    <p>Image compression aims to reduce the amount of data required to represent an image while preserving its visual quality. SVD offers a powerful technique for achieving this. It decomposes the image into its essential components, allowing us to discard less important parts for compression and reconstruct an approximation later.</p>
                    <p>Least squares approximations help us quantify the error introduced by discarding information during compression.</p>
                    <h3 id="the-basic-concept-overview-">The Basic Concept Overview:</h3>
                    <p>Imagine a grayscale image as a matrix ( A ). SVD decomposes it into three matrices:</p>
                    <ol>
                    <li><strong>U (Left Singular Vectors):</strong> An orthogonal matrix representing the directions of important variations in the image.</li>
                    <li><strong>Σ (Singular Values):</strong> A diagonal matrix containing values representing the significance of each direction (U vector) in capturing the image&#39;s information. Larger values indicate more importance.</li>
                    <li><strong>V^T (Right Singular Vectors):</strong> The transpose of another orthogonal matrix, related to how the image data is distributed across the directions in ( U ).</li>
                    </ol>
                    <p>By keeping only the top ( k ) largest singular values in ( \Sigma ) and setting the rest to zero, we create a compressed representation ( A_k ) of the original image. This captures the most important information with a smaller data size.</p>
                    <h3 id="a-mathematical-overview-">A Mathematical Overview:</h3>
                    <ol>
                    <li><strong>Singular Value Decomposition (SVD):</strong></li>
                    </ol>
                    <p>A = U Σ V^T</p>
                    <p>where:
                    ○ A: Original image matrix (e.g., 4x4 for a 4x4 grayscale image)
                    ○ U: Left singular vectors matrix (size same as A)
                    ○ Σ: Diagonal matrix containing singular values (size same as A, but only non-zero values on the diagonal)
                    ○ V^T: Transpose of right singular vectors matrix (size same as A)</p>
                    <ol>
                    <li><strong>Compressed Representation:</strong></li>
                    </ol>
                    <p>Σ_k = diag(σ_1, σ_2, ..., σ_k, 0, ..., 0) // Top k singular values
                    A_k = U Σ_k V^T</p>
                    <p>where:
                    ○ Σ_k: Diagonal matrix containing only the top k singular values from Σ.
                    ○ A_k: Compressed representation of the original image.</p>
                    <ol>
                    <li><strong>Least Squares Approximation and Error:</strong></li>
                    </ol>
                    <p>Reconstruction: Approximate the original image from the compressed form:</p>
                    <p>A_k_approx = U Σ_k V^T</p>
                    <p>○ where:
                    ■ A_k_approx: Reconstructed approximation of the original image.
                    Mean Squared Error (MSE): Quantify the difference between original and reconstructed image:</p>
                    <p>MSE = (1 / (m <em> n)) </em> || A - A_k_approx ||^2 // m, n are image dimensions</p>
                    <p>○ where:
                    ■ MSE: Mean Squared Error || ||^2: Squared Frobenius norm (measures matrix difference)
                    By analyzing the MSE for different compression levels (different k values), we can determine the optimal compression ratio that balances image quality and file size.</p>
                    <h3 id="pythonic-code-">Pythonic Code:</h3>
                    <h4 id="step-1-load-and-preprocess-the-image">Step 1: Load and Preprocess the Image</h4>
                    <p>We start by loading the image from a URL and converting it to grayscale using the <code>load_image</code> function. Grayscale conversion is necessary because SVD works on single-channel images.</p>
                    <pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy as np
                    <span class="hljs-keyword">import</span> matplotlib.pyplot as plt
                    from skimage <span class="hljs-keyword">import</span> io, <span class="hljs-built_in">color</span>, img_as_float
                    <span class="hljs-keyword">import</span> imageio

                    def load_image(url):
                        <span class="hljs-built_in">image</span> = io.imread(url)
                        <span class="hljs-keyword">if</span> <span class="hljs-built_in">image</span>.ndim == <span class="hljs-number">3</span>:
                            <span class="hljs-built_in">image</span> = <span class="hljs-built_in">color</span>.rgb2gray(<span class="hljs-built_in">image</span>)
                        <span class="hljs-keyword">return</span> img_as_float(<span class="hljs-built_in">image</span>)
                    </code></pre>
                    <h4 id="step-2-compute-singular-value-decomposition-svd-">Step 2: Compute Singular Value Decomposition (SVD)</h4>
                    <pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_svd</span><span class="hljs-params">(image)</span>:</span>
                        U, S, Vt = np.linalg.svd(image, full_matrices=<span class="hljs-keyword">False</span>)
                        <span class="hljs-keyword">return</span> U, S, Vt
                    </code></pre>
                    <h4 id="step-3-reconstruct-image-using-top-k-singular-values">Step 3: Reconstruct Image Using Top k Singular Values</h4>
                    <pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reconstruct_image</span><span class="hljs-params">(U, S, Vt, k)</span></span>:
                        <span class="hljs-keyword">return</span> np.dot(U[<span class="hljs-symbol">:</span>, <span class="hljs-symbol">:k</span>], np.dot(np.diag(S[<span class="hljs-symbol">:k</span>]), Vt[<span class="hljs-symbol">:k</span>, <span class="hljs-symbol">:</span>]))
                    </code></pre>
                    <h4 id="step-4-compute-the-least-squares-error">Step 4: Compute the Least Squares Error</h4>
                    <pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_error</span><span class="hljs-params">(original, reconstructed)</span></span>:
                        <span class="hljs-keyword">return</span> np.linalg.norm(original - reconstructed)
                    </code></pre>
                    <h4 id="step-5-compute-explained-variance-ratio">Step 5: Compute Explained Variance Ratio</h4>
                    <pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">explained_variance_ratio</span><span class="hljs-params">(S, k)</span></span>:
                        <span class="hljs-keyword">return</span> np.sum(S[<span class="hljs-symbol">:k</span>]**<span class="hljs-number">2</span>) / np.sum(S**<span class="hljs-number">2</span>)
                    </code></pre>
                    <h4 id="step-6-display-and-save-results">Step 6: Display and Save Results</h4>
                    <pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">display_and_save_results</span><span class="hljs-params">(original, reconstructed, k, error, explained_variance)</span></span>:
                        fig, axes = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>))
                        <span class="hljs-comment"># Display original image</span>
                        axes[<span class="hljs-number">0</span>].imshow(original, cmap=<span class="hljs-string">'gray'</span>)
                        axes[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">'Original Image'</span>)
                        axes[<span class="hljs-number">0</span>].axis(<span class="hljs-string">'off'</span>)
                        <span class="hljs-comment"># Display reconstructed image</span>
                        axes[<span class="hljs-number">1</span>].imshow(reconstructed, cmap=<span class="hljs-string">'gray'</span>)
                        axes[<span class="hljs-number">1</span>].set_title(f<span class="hljs-string">'Reconstructed Image (k={k})'</span>)
                        axes[<span class="hljs-number">1</span>].axis(<span class="hljs-string">'off'</span>)
                        fig.suptitle(f<span class="hljs-string">'k={k}, Error={error:.2f}, Explained Variance={explained_variance:.2%}'</span>)
                        plt.show()
                        <span class="hljs-comment"># Save the figure</span>
                        fig.savefig(f<span class="hljs-string">'result_k_{k}.jpg'</span>)
                        plt.close(fig)
                        <span class="hljs-comment"># Save the reconstructed image as a jpg file</span>
                        imageio.imwrite(f<span class="hljs-string">'reconstructed_image_k_{k}.jpg'</span>, (reconstructed * <span class="hljs-number">255</span>).astype(np.uint8))
                    </code></pre>
                    <h4 id="step-7-plot-metrics">Step 7: Plot Metrics</h4>
                    <pre><code class="lang-python">def plot_metrics(singular_values, errors, explained_variances):
                        fig, ax1 = plt.subplots()
                        <span class="hljs-keyword">color</span> = <span class="hljs-string">'tab:blue'</span>
                        ax1.set_xlabel(<span class="hljs-string">'k (number of singular values)'</span>)
                        ax1.set_ylabel(<span class="hljs-string">'Error'</span>, <span class="hljs-keyword">color</span>=<span class="hljs-keyword">color</span>)
                        ax1.plot(singular_values, errors, <span class="hljs-keyword">color</span>=<span class="hljs-keyword">color</span>, marker=<span class="hljs-string">'o'</span>, linestyle=<span class="hljs-string">'-'</span>, label=<span class="hljs-string">'Error'</span>)
                        ax1.tick_params(axis=<span class="hljs-string">'y'</span>, labelcolor=<span class="hljs-keyword">color</span>)
                        ax2 = ax1.twinx()  <span class="hljs-meta"># instantiate a second axes that shares the same x-axis</span>
                        <span class="hljs-keyword">color</span> = <span class="hljs-string">'tab:orange'</span>
                        ax2.set_ylabel(<span class="hljs-string">'Explained Variance Ratio'</span>, <span class="hljs-keyword">color</span>=<span class="hljs-keyword">color</span>)  <span class="hljs-meta"># we already handled the x-label with ax1</span>
                        ax2.plot(singular_values, explained_variances, <span class="hljs-keyword">color</span>=<span class="hljs-keyword">color</span>, marker=<span class="hljs-string">'o'</span>, linestyle=<span class="hljs-string">'-'</span>, label=<span class="hljs-string">'Explained Variance Ratio'</span>)
                        ax2.tick_params(axis=<span class="hljs-string">'y'</span>, labelcolor=<span class="hljs-keyword">color</span>)
                        fig.tight_layout()  <span class="hljs-meta"># otherwise the right y-label is slightly clipped</span>
                        plt.title(<span class="hljs-string">'Error and Explained Variance Ratio vs k'</span>)
                        plt.show()
                    </code></pre>
                    <h3 id="outputs-generated">Outputs Generated</h3>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/5f9c0d19-711b-494c-9caa-4b9202542503" alt="image">                <img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/ae2a3d4f-3c0d-4c28-9ff0-0705e66f6da0" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/9b5d7e81-f9ff-46ef-9460-570dfcfe852d" alt="image">                <img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/da1bc73d-23f0-4df5-b6d3-2a83eb18d2a1" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/2091d3b3-e8f8-4496-950d-0dadc5b9bdde" alt="image">                <img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/3abdbbe4-308d-4eb5-bf2b-32aed4c46c8d" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/aa599b39-2eec-4128-b255-8f6c512d77e8" alt="image"></p>
                    <h3 id="inference-from-the-dual-line-plot">Inference from the Dual Line Plot</h3>
                    <p><img src="https://github.com/MirshaMorningstar/SVD_Gram-Schmidt-Orthogonalization_Least-Square-Approximation/assets/84216040/38b2288b-22f4-442d-989b-156258954100" alt="image"></p>
                    <p>The dual line plot shows the relationship between the number of singular values (( k )), the reconstruction error, and the explained variance ratio. Here&#39;s a detailed analysis:</p>
                    <p><strong>Error Analysis:</strong></p>
                    <ul>
                    <li>The reconstruction error (blue line) starts high when ( k ) is low and decreases rapidly as ( k ) increases.</li>
                    <li>The error drops significantly between ( k = 5 ) and ( k = 100 ).</li>
                    <li>After ( k = 100 ), the error decreases more gradually and stabilizes around a very low value.</li>
                    </ul>
                    <p><strong>Explained Variance Ratio:</strong></p>
                    <ul>
                    <li>The explained variance ratio (orange line) increases sharply at the beginning.</li>
                    <li>By ( k = 50 ), the explained variance ratio is already very close to 1 (almost 99.9%).</li>
                    <li>After ( k = 100 ), the explained variance ratio changes very little, indicating that most of the variance in the image is already captured.</li>
                    </ul>
                    <p><strong>Conclusion on When to Stop:</strong>
                    To achieve a good balance between image quality and compression, we should choose a k where the error is low and the explained variance ratio is high.
                    From the plot, k = 50 captures almost all the variance (99.9%) while significantly reducing the error. This suggests that k = 50 provides a good compressed image with minimal visual loss.</p>
                    <p><strong>Visual Loss and Compression:</strong>
                    Beyond k = 100, the improvement in image quality becomes marginal as the error reduction is minimal, and the explained variance ratio is almost constant.</p>
                    <p>Therefore, using more than 100 singular values does not substantially improve the visual quality but increases the computational cost and storage size.</p>

                



                </div>
            </div>
        </div>
    </div>

    <!-- Project 6 Modal -->
    <div class="modal fade" id="project6Modal" tabindex="-1" aria-labelledby="project6ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="project6ModalLabel"> 3D Point Cloud Analysis and Processing</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Technologies:</strong> Python, ML, AI, Graphs, LiDAR, Object Classification, Part Segmentation, Semantic Segmentation, Graph Neural Networks, Deep Learning, Data Visualisation and Exploration, Plotly</p>
                    <p><strong>Project Github Repository: <a href="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-">Project Link</a></strong></p>
                    <p><strong>Description:</strong> An Extensive deep dive into Object Classification, Part Segmentation, and Semantic Segmentation with PointNet and DG CNN Deep Learning Models.</p>
                    <img src="assets/object_classification.png" alt="Project 3 Photo">
                </div>

                <div class="modal-body">
                    <h1 id="3d-point-cloud-analysis-and-processing">3D Point Cloud Analysis and Processing</h1>
                    <p>Object Classification, Part Segmentation, and Semantic Segmentation with PointNet and DG CNN Deep Learning Models</p>
                    <h2 id="table-of-contents">Table of Contents</h2>
                    <ul>
                    <li><a href="#introduction">Introduction</a><ul>
                    <li><a href="#overview-of-point-clouds-in-3d-data-analysis">Overview of Point Clouds in 3D Data Analysis</a></li>
                    <li><a href="#point-cloud-representation-and-significance-in-real-world-data">Point Cloud Representation and Significance in Real-world Data</a></li>
                    <li><a href="#applications-across-various-industries">Applications across Various Industries</a></li>
                    <li><a href="#importance-of-object-classification-and-segmentation">Importance of Object Classification and Segmentation</a></li>
                    <li><a href="#brief-introduction-to-pointnet-and-dg-cnn">Brief Introduction to PointNet and DG-CNN</a></li>
                    <li><a href="#other-models-used-for-processing-point-cloud-data">Other Models used for processing Point Cloud Data</a></li>
                    </ul>
                    </li>
                    <li><a href="#datasets-used">Datasets Used</a><ul>
                    <li><a href="#shapenet-dataset-description-characteristics-and-applications">ShapeNet Dataset: Description, Characteristics and Applications</a></li>
                    <li><a href="#modelnet10-dataset-description-characteristics-and-applications">ModelNet10 Dataset: Description, Characteristics and Applications</a></li>
                    <li><a href="#dales-dataset-description-characteristics-and-applications">DALES Dataset: Description, Characteristics and Applications</a></li>
                    </ul>
                    </li>
                    <li><a href="#object-classification-with-point-clouds">Object Classification with Point Clouds</a><ul>
                    <li><a href="#experimental-setup-for-object-classification">Experimental Setup for Object Classification</a></li>
                    <li><a href="#results-and-performance-metrics-on-shapenet-and-modelnet10">Results and Performance Metrics on ShapeNet and ModelNet10</a></li>
                    <li><a href="#comparison-between-pointnet-and-dgcnn">Comparison Between PointNet and DGCNN</a></li>
                    </ul>
                    </li>
                    <li><a href="#part-segmentation-using-point-clouds">Part Segmentation Using Point Clouds</a><ul>
                    <li><a href="#description-of-part-segmentation-task">Description of Part Segmentation Task</a></li>
                    <li><a href="#implementation-details-for-part-segmentation">Implementation Details for Part Segmentation</a></li>
                    <li><a href="#evaluation-metrics-and-results-analysis">Evaluation Metrics and Results Analysis</a></li>
                    </ul>
                    </li>
                    <li><a href="#semantic-segmentation-on-dales-dataset">Semantic Segmentation on DALES Dataset</a><ul>
                    <li><a href="#introduction-to-semantic-segmentation">Introduction to Semantic Segmentation</a></li>
                    <li><a href="#application-of-pointnet-and-dgcnn-on-dales-dataset">Application of PointNet and DGCNN on DALES Dataset</a></li>
                    <li><a href="#evaluation-metrics-and-performance-analysis">Evaluation Metrics and Performance Analysis</a></li>
                    </ul>
                    </li>
                    <li><a href="#our-special-approach">Our Special Approach</a><ul>
                    <li><a href="#data-preprocessing">Data Preprocessing</a></li>
                    <li><a href="#data-cleaning-and-transformation">Data Cleaning and Transformation</a></li>
                    <li><a href="#training-batch-preparation">Training Batch Preparation</a></li>
                    </ul>
                    </li>
                    <li><a href="#general-comparison-between-pointnet-and-dg-cnn">General Comparison Between PointNet and DG-CNN</a><ul>
                    <li><a href="#strengths-of-pointnet">Strengths of PointNet</a></li>
                    <li><a href="#strengths-of-dgcnn">Strengths of DGCNN</a></li>
                    <li><a href="#computational-efficiency">Computational Efficiency</a></li>
                    <li><a href="#generalizability">Generalizability</a></li>
                    <li><a href="#accuracy-comparison">Accuracy comparison</a></li>
                    </ul>
                    </li>
                    <li><a href="#specific-comparison-between-pointnet-and-dg-cnn-and-discussion">Specific Comparison Between PointNet and DG-CNN and Discussion</a><ul>
                    <li><a href="#architecture---comparison-and-complexity-analysis">Architecture - Comparison and complexity analysis</a></li>
                    <li><a href="#comparative-study-of-pointnet-and-dgcnn-performance">Comparative Study of PointNet and DGCNN Performance</a></li>
                    </ul>
                    </li>
                    <li><a href="#conclusion">Conclusion</a></li>
                    <li><a href="#citations-and-sources-references">Citations and Sources References</a></li>
                    </ul>
                    <h2 id="introduction">Introduction</h2>
                    <h3 id="overview-of-point-clouds-in-3d-data-analysis">Overview of Point Clouds in 3D Data Analysis</h3>
                    <p>Point clouds are fundamental components in the realm of 3D data analysis, representing a collection of data points in a three-dimensional space. These points, typically derived from sensors like LiDAR (Light Detection and Ranging) or depth cameras, collectively form a detailed representation of surfaces, objects, or environments. The structure and arrangement of these points provide intricate spatial information crucial for various applications.</p>
                    <h3 id="point-cloud-representation-and-significance-in-real-world-data">Point Cloud Representation and Significance in Real-world Data</h3>
                    <p>The representation of real-world objects or scenes in the form of point clouds holds significant importance. Point clouds serve as a rich and accurate depiction of the physical world, capturing detailed geometric information with precision. This representation method allows for the preservation of spatial relationships and fine details, making point clouds an invaluable tool in various fields of study and industry applications.</p>
                    <h3 id="applications-across-various-industries">Applications across Various Industries</h3>
                    <h4 id="robotics">Robotics</h4>
                    <p>In robotics, point clouds are instrumental in tasks such as environment mapping, localization, and navigation. Robots equipped with sensors capable of generating point clouds can perceive their surroundings, enabling them to make informed decisions and interact with the environment more effectively.</p>
                    <h4 id="autonomous-vehicles">Autonomous Vehicles</h4>
                    <p>Point clouds play a pivotal role in the development and operation of autonomous vehicles. They aid in environmental perception, helping these vehicles understand and interpret their surroundings. By analyzing point cloud data, autonomous vehicles can detect obstacles, recognize lanes, and navigate safely through complex environments.</p>
                    <h4 id="healthcare">Healthcare</h4>
                    <p>Within healthcare, point clouds find applications in medical imaging and analysis. They contribute to creating detailed 3D models of anatomical structures, facilitating surgical planning, diagnostics, and treatment. Point cloud-based imaging techniques enhance the accuracy and depth of medical imaging, allowing for better understanding and visualization of patient-specific conditions.</p>
                    <h3 id="importance-of-object-classification-and-segmentation">Importance of Object Classification and Segmentation</h3>
                    <h4 id="object-classification">Object Classification</h4>
                    <p>Object classification within point clouds involves the categorization or labeling of individual objects or elements present in a 3D scene. This process is fundamental in understanding the environment and identifying specific entities within it. By assigning categories or classes to objects, it enables machines to recognize and differentiate between various elements, laying the foundation for more sophisticated analysis and decision-making.</p>
                    <h4 id="segmentation">Segmentation</h4>
                    <p>Segmentation in point clouds involves dividing the continuous point cloud data into meaningful segments or regions based on shared properties such as color, shape, or spatial proximity. This segmentation allows for a more granular understanding of the scene by breaking it down into distinct components, enabling targeted analysis and manipulation of individual parts within the larger point cloud.</p>
                    <h3 id="brief-introduction-to-pointnet-and-dgcnn">Brief Introduction to PointNet and DGCNN</h3>
                    <h4 id="pointnet">PointNet</h4>
                    <p>PointNet is a pioneering neural network architecture designed specifically to process point cloud data directly. Unlike traditional methods that rely on converting point clouds to other formats, PointNet directly consumes raw point cloud data as input, preserving spatial relationships. It excels in tasks like object classification and part segmentation by efficiently processing unordered point sets through a series of neural network layers, capturing global and local features effectively.</p>
                    <h4 id="dgcnn-dynamic-graph-cnn-">DGCNN (Dynamic Graph CNN)</h4>
                    <p>DGCNN, or Dynamic Graph Convolutional Neural Network, is another influential architecture tailored for point cloud analysis. It leverages graph-based convolutions to learn hierarchical representations of point clouds. By constructing a nearest neighbor graph and dynamically updating it during training, DGCNN can capture local and global features while maintaining permutation invariance, making it well-suited for tasks like semantic segmentation and object recognition within point clouds. These methodologies, PointNet and DGCNN, represent significant advancements in the field of point cloud analysis, providing efficient and effective ways to handle object classification, part segmentation, and semantic understanding within 3D data.</p>
                    <h3 id="other-models-used-for-processing-point-cloud-data">Other Models used for processing Point Cloud Data</h3>
                    <h4 id="pointnet-">PointNet++</h4>
                    <ul>
                    <li><strong>Approach</strong>: Hierarchically samples and processes local neighborhoods to capture detailed local features before aggregating them for global understanding.</li>
                    <li><strong>Strengths</strong>: Improved ability to capture local structures through hierarchical feature learning, handles both local and global contexts.</li>
                    <li><strong>Improvements Over PointNet</strong>: Addresses PointNet&#39;s limitation by focusing on local regions and iterative hierarchical feature extraction.</li>
                    </ul>
                    <h4 id="pointcnn">PointCNN</h4>
                    <ul>
                    <li><strong>Approach</strong>: Utilizes hierarchical clustering and learns features through a learnable upsampling and downsampling strategy.</li>
                    <li><strong>Strengths</strong>: Efficiently captures local features, adapts to varying densities in point clouds.</li>
                    <li><strong>Key Feature</strong>: Focuses on hierarchical sampling, robust in handling varying point densities.</li>
                    </ul>
                    <p><strong>Summary of Differences:</strong></p>
                    <ul>
                    <li><strong>PointNet vs. PointNet++</strong>: PointNet processes points globally, while PointNet++ hierarchically captures local structures before aggregating for global understanding.</li>
                    <li><strong>PointNet++ vs. DGCNN</strong>: PointNet++ focuses on hierarchical local feature learning, whereas DGCNN constructs dynamic graphs and uses edge convolutions for understanding point relationships.</li>
                    <li><strong>DGCNN vs. PointCNN</strong>: DGCNN operates on dynamic graphs for spatial understanding, while PointCNN uses hierarchical clustering and a learnable sampling strategy to capture local features efficiently.</li>
                    </ul>
                    <h2 id="datasets-used">Datasets Used</h2>
                    <h3 id="shapenet-dataset-description-characteristics-and-applications">ShapeNet Dataset: Description, Characteristics and Applications</h3>
                    <h4 id="description">Description</h4>
                    <ul>
                    <li>A large-scale, richly-annotated 3D model dataset with over 50,000 unique 3D models.</li>
                    <li>Models are organized into over 55 categories, representing common objects, furniture, vehicles, and more.</li>
                    <li>Provides both CAD models and aligned RGB-D images for many objects.</li>
                    </ul>
                    <p><img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/6bae46c0-6c78-4117-9105-1b0a14eb557d" alt="image"></p>
                    <h4 id="characteristics">Characteristics</h4>
                    <ul>
                    <li><strong>Size</strong>: Over 2 million 3D models</li>
                    <li><strong>Format</strong>: OBJ, PLY, and VRML</li>
                    <li><strong>Annotations</strong>: Category labels, object parts, and 3D keypoints</li>
                    <li><strong>Licensing</strong>: Creative Commons Attribution 4.0 International</li>
                    </ul>
                    <h4 id="point-cloud-applications">Point Cloud Applications</h4>
                    <ul>
                    <li>3D object recognition</li>
                    <li>Shape analysis</li>
                    <li>3D scene understanding</li>
                    <li>Object detection and segmentation</li>
                    <li>Virtual and augmented reality</li>
                    </ul>
                    <h3 id="modelnet10-dataset-description-characteristics-and-applications">ModelNet10 Dataset: Description, Characteristics and Applications</h3>
                    <h4 id="description">Description</h4>
                    <ul>
                    <li>A subset of ShapeNet, containing 4,899 3D CAD models from 10 categories.</li>
                    <li>Commonly used for 3D object classification and shape retrieval tasks.</li>
                    </ul>
                    <h4 id="dataset-applications">Dataset Applications</h4>
                    <p><img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/3d0bda34-5e85-4295-a8c5-1c3b89fe51ed" alt="image"></p>
                    <ul>
                    <li>3D object classification</li>
                    <li>3D shape retrieval</li>
                    <li>3D point cloud processing</li>
                    <li>3D deep learning</li>
                    </ul>
                    <h3 id="dales-dataset-description-characteristics-and-applications">DALES Dataset: Description, Characteristics and Applications</h3>
                    <h4 id="description">Description</h4>
                    <ul>
                    <li><p>The Dayton Annotated Laser Earth Scan (DALES) data set, a new large-scale aerial LiDAR data set with nearly a half-billion points spanning 10 square kilometers of area. DALES contains forty scenes of dense, labeled aerial data spanning multiple scene types, including urban, suburban, rural, and commercial. The data was hand-labeled by a team of expert LiDAR technicians into eight categories: ground, vegetation, cars, trucks, poles, power lines, fences, and buildings. We present the entire data set, split into testing and training, and provided in 3 different data formats. The goal of this data set is to help advance the field of deep learning within aerial LiDAR.</p>
                    </li>
                    <li><p>There are two sets of data covering the same geographical area:</p>
                    <ul>
                    <li>DALES: the original dataset containing semantic segmentation labels.</li>
                    <li>DALES Objects: the second version contains semantic labels, instance labels, and intensity data.</li>
                    </ul>
                    </li>
                    <li><p>A multi-view dataset of 3D objects, specifically designed for learning 3D representations from multiple views.</p>
                    </li>
                    <li>Contains 150,000 images of 100 objects, captured from 54 different viewpoints.</li>
                    </ul>
                    <h4 id="key-features">Key Features</h4>
                    <ul>
                    <li><strong>Multi-view images</strong>: Provides images of objects from various angles.</li>
                    <li><strong>Dense object correspondences</strong>: Contains pixel-level correspondences between object parts across different views.</li>
                    <li><strong>Ground truth 3D models</strong>: Includes accurate 3D models of all objects.</li>
                    </ul>
                    <h4 id="dataset-applications">Dataset Applications</h4>
                    <ul>
                    <li>3D object reconstruction</li>
                    <li>3D shape prediction</li>
                    <li>View synthesis</li>
                    <li>3D pose estimation</li>
                    <li>3D scene understanding</li>
                    </ul>
                    <h2 id="object-classification-with-point-clouds">Object Classification with Point Clouds</h2>
                    <h3 id="experimental-setup-for-object-classification">Experimental Setup for Object Classification</h3>
                    <p>The experimental setup for object classification involves preparing the datasets (such as ShapeNet and ModelNet10), preprocessing the point cloud data, and configuring the neural network models (PointNet and DGCNN) for the classification task. This setup includes defining training/validation/testing splits, data augmentation strategies, hyperparameter tuning, and establishing evaluation protocols.</p>
                    <h3 id="dataset-preparation-">Dataset Preparation:</h3>
                    <ul>
                    <li><p><strong>ShapeNet</strong>:</p>
                    <ul>
                    <li>Total objects: 50,000+</li>
                    <li>Categories: 55+</li>
                    <li>Format: OBJ, PLY, VRML</li>
                    <li>Preprocessing: Centering, rescaling to unit sphere, random sampling (e.g., 1024 points per object)</li>
                    </ul>
                    </li>
                    <li><p><strong>ModelNet10</strong>:</p>
                    <ul>
                    <li>Total objects: 4,899</li>
                    <li>Categories: 10</li>
                    <li>Format: OFF</li>
                    <li>Preprocessing: Similar to ShapeNet</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="data-augmentation-">Data Augmentation:</h3>
                    <ul>
                    <li>Random rotations: Along x, y, and z axes (range: 0-360 degrees)</li>
                    <li>Random scaling: Uniform scaling within a range (e.g., 0.8-1.2)</li>
                    <li>Random jittering: Adding Gaussian noise to point coordinates (standard deviation: 0.01-0.05)</li>
                    </ul>
                    <h3 id="hyperparameter-tuning-">Hyperparameter Tuning:</h3>
                    <ul>
                    <li>Learning rate: Common values: 0.001-0.01, with decay schedules (e.g., cosine annealing)</li>
                    <li>Batch size: Dependent on GPU memory, often 16-32</li>
                    <li>Number of layers: Dependent on model architecture and dataset complexity</li>
                    </ul>
                    <h3 id="evaluation-protocol-">Evaluation Protocol:</h3>
                    <ul>
                    <li>Cross-validation: 5-fold or 10-fold for reliable performance estimates</li>
                    <li>Metrics: Accuracy, precision, recall, F1-score, confusion matrices</li>
                    </ul>
                    <p><img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/3b940caf-9d3b-4f56-9448-d73dec261e00" alt="image"></p>
                    <h2 id="results-and-performance-metrics-on-shapenet-and-modelnet10">Results and Performance Metrics on ShapeNet and ModelNet10</h2>
                    <p>The evaluation of object classification performance on ShapeNet and ModelNet10 datasets includes assessing metrics like accuracy, precision, recall, and F1-score. Results indicate the effectiveness of PointNet and DGCNN in accurately classifying objects within point clouds. Additionally, visualizations or confusion matrices might be presented to illustrate the models&#39; performance across different object categories.</p>
                    <h3 id="shapenet-">ShapeNet:</h3>
                    <ul>
                    <li>PointNet: Accuracy ~89%, F1-score ~88%</li>
                    <li>DGCNN: Accuracy ~94%, F1-score ~93%</li>
                    </ul>
                    <h3 id="modelnet10-">ModelNet10:</h3>
                    <ul>
                    <li>PointNet: Accuracy ~90%, F1-score ~90%</li>
                    <li>DGCNN: Accuracy ~98.9%, F1-score ~97.5%</li>
                    </ul>
                    <h2 id="comparison-between-pointnet-and-dgcnn">Comparison Between PointNet and DGCNN</h2>
                    <p>A comparative analysis between PointNet and DGCNN involves evaluating their performance metrics on object classification tasks, discussing their strengths and weaknesses, computational efficiency, and generalizability. Highlighting the advantages and limitations of each model in terms of handling point cloud data for object classification purposes aids in understanding their suitability for different applications and datasets.</p>
                    <h3 id="strengths-of-pointnet-">Strengths of PointNet:</h3>
                    <ul>
                    <li>Simpler architecture, faster training and inference</li>
                    <li>Effective for global feature extraction</li>
                    <li>Well-suited for large-scale point clouds</li>
                    </ul>
                    <h3 id="strengths-of-dgcnn-">Strengths of DGCNN:</h3>
                    <ul>
                    <li>Superior capture of local geometric structures</li>
                    <li>More robust to noise and occlusion</li>
                    <li>Often achieves higher accuracy on complex datasets</li>
                    </ul>
                    <h3 id="computational-efficiency-">Computational Efficiency:</h3>
                    <ul>
                    <li>PointNet generally faster than DGCNN</li>
                    <li>Trade-off between accuracy and speed to consider</li>
                    </ul>
                    <h3 id="generalizability-">Generalizability:</h3>
                    <ul>
                    <li>DGCNN may generalize better to unseen data due to local feature focus</li>
                    <li>PointNet&#39;s global features might be less adaptable</li>
                    </ul>
                    <h3 id="data-characteristics-">Data Characteristics:</h3>
                    <ul>
                    <li>Choice of model depends on dataset complexity and task requirements</li>
                    <li>DGCNN often favored for datasets with fine-grained details and noise</li>
                    <li>PointNet suitable for large-scale datasets where speed is critical</li>
                    </ul>
                    <h2 id="part-segmentation-using-point-clouds">Part Segmentation Using Point Clouds</h2>
                    <h3 id="description-of-part-segmentation-task">Description of Part Segmentation Task</h3>
                    <p>Part segmentation within point clouds involves dividing objects into constituent parts or components. This task aims to assign a specific label or category to each point in the point cloud, indicating the part of the object it belongs to. It&#39;s crucial for fine-grained understanding and analysis of object structures, enabling applications like robotics, manufacturing, and 3D modeling.</p>
                    <p>Objective: Decompose a 3D object represented as a point cloud into its constituent parts, assigning a unique label to each point indicating its part membership.</p>
                    <p>Applications:</p>
                    <ul>
                    <li>3D object analysis</li>
                    <li>Scene understanding</li>
                    <li>Virtual and augmented reality</li>
                    <li>Robotic manipulation</li>
                    </ul>
                    <p>Challenges:</p>
                    <ul>
                    <li>Diverse object shapes and structures</li>
                    <li>Varying part sizes and complexities</li>
                    <li>Noise and occlusion in point cloud data</li>
                    <li>Maintaining part boundaries and geometric relationships</li>
                    </ul>
                    <h3 id="implementation-details-for-part-segmentation">Implementation Details for Part Segmentation</h3>
                    <p>Implementing part segmentation involves configuring PointNet and DGCNN architectures for handling part-level labeling within point clouds. This includes modifying network layers, handling multi-label outputs, defining loss functions, and optimizing the models for the segmentation task. Preprocessing steps might involve data augmentation techniques specific to part-level annotation.</p>
                    <h3 id="dataset-preparation-">Dataset Preparation:</h3>
                    <ul>
                    <li>Load datasets with part annotations (e.g., ModelNet10, ShapeNetPart).</li>
                    <li>Preprocess point clouds (normalization, sampling).</li>
                    <li>Split into training, validation, and testing sets.</li>
                    </ul>
                    <h3 id="model-architecture-">Model Architecture:</h3>
                    <ul>
                    <li>Use PointNet or DGCNN as backbone architectures.</li>
                    <li>Adapt final layers for part segmentation:<ul>
                    <li>PointNet: Output per-point segmentation scores.</li>
                    <li>DGCNN: Employ multi-scale feature aggregation for refined segmentation.</li>
                    </ul>
                    </li>
                    </ul>
                    <h3 id="loss-function-">Loss Function:</h3>
                    <ul>
                    <li>Use cross-entropy loss for multi-class segmentation.</li>
                    <li>Consider Dice loss or focal loss for handling class imbalance.</li>
                    </ul>
                    <h3 id="training-">Training:</h3>
                    <ul>
                    <li>Optimize with Adam optimizer or variants.</li>
                    <li>Employ learning rate scheduling and regularization.</li>
                    <li>Monitor performance on validation set for early stopping.</li>
                    </ul>
                    <h3 id="evaluation-metrics-and-results-analysis">Evaluation Metrics and Results Analysis</h3>
                    <p><img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/47adf844-427d-4dca-b2ac-76ebe4b0f85e" alt="image"></p>
                    <p><img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/7282e178-dbbf-4fc7-a977-eacf2dfce2b5" alt="image">        <img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/7a58d186-45ad-4f71-9dcc-127f6dbbb8ad" alt="image"></p>
                    <p>Evaluation metrics for part segmentation include IoU (Intersection over Union), mean IoU, per-category IoU, precision, recall, and accuracy. Results from experiments on benchmark datasets, along with visualizations of segmented parts, help analyze the models&#39; performance in accurately delineating object parts within point clouds.</p>
                    <h3 id="metrics-">Metrics:</h3>
                    <ul>
                    <li>Intersection over Union (IoU): Measures overlap between predicted and ground truth segments.</li>
                    <li>Mean IoU (mIoU): Average IoU across all part categories.</li>
                    <li>Precision and recall: Assess model&#39;s ability to correctly identify true positives and negatives.</li>
                    </ul>
                    <h3 id="key-findings-">Key Findings:</h3>
                    <ul>
                    <li>Both PointNet and DGCNN achieve good segmentation results, but DGCNN often outperforms PointNet due to its focus on local features.</li>
                    <li>Performance varies across different object categories and dataset complexities.</li>
                    <li>Visualizations (e.g., colored segmentation masks) provide qualitative insights into model performance.</li>
                    </ul>
                    <h2 id="introduction-to-semantic-segmentation">Introduction to Semantic Segmentation</h2>
                    <p>Semantic segmentation in the context of point clouds involves assigning a specific semantic label to each point, effectively partitioning the 3D space into meaningful segments based on semantic categories. This task is crucial for scene understanding, where each point is classified into object classes or categories, enabling detailed analysis and comprehension of the environment.</p>
                    <p>Definition: The task of assigning a semantic label (e.g., &quot;car,&quot; &quot;building,&quot; &quot;tree&quot;) to each point in a point cloud, resulting in a dense, pixel-like labeling of the 3D scene.</p>
                    <p>Applications:</p>
                    <ul>
                    <li>Autonomous driving</li>
                    <li>Robotics</li>
                    <li>3D scene understanding</li>
                    <li>Urban planning</li>
                    <li>Infrastructure management</li>
                    </ul>
                    <p>Challenges:</p>
                    <ul>
                    <li>Large-scale, complex point clouds</li>
                    <li>Diverse object categories and shapes</li>
                    <li>Varying point densities and noise levels</li>
                    <li>Irregular data structure</li>
                    </ul>
                    <h2 id="application-of-pointnet-and-dgcnn-on-dales-dataset">Application of PointNet and DGCNN on DALES Dataset</h2>
                    <p>Utilizing PointNet and DGCNN for semantic segmentation on the DALES dataset involves adapting these architectures to handle the semantic labeling of points within complex real-world scenes captured by sensors like LiDAR. Preprocessing steps may include data augmentation, normalization, and suitable formatting of input and output labels to match the semantic annotation scheme of the dataset.</p>
                    <h3 id="dales-dataset-">DALES Dataset:</h3>
                    <ul>
                    <li>Large-scale aerial LiDAR dataset with over 500 million hand-labeled points.</li>
                    <li>Captures urban scenes with buildings, vegetation, cars, roads, power lines, etc.</li>
                    <li>Presents challenges due to density, noise, and unstructured nature of aerial LiDAR data.</li>
                    </ul>
                    <h3 id="model-adaptation-">Model Adaptation:</h3>
                    <ul>
                    <li>Use PointNet or DGCNN as backbone architectures.</li>
                    <li>Modify output layers to produce per-point semantic segmentation scores.</li>
                    <li>Adapt hyperparameters and training strategies for aerial LiDAR data.</li>
                    </ul>
                    <h2 id="evaluation-metrics-and-performance-analysis">Evaluation Metrics and Performance Analysis</h2>
                    <p>Evaluation metrics for semantic segmentation include IoU (Intersection over Union), mean IoU across different semantic categories, pixel accuracy, precision, and recall. Performance analysis involves assessing how accurately PointNet and DGCNN segment different objects or scene elements within the DALES dataset. Visualizations and qualitative assessments of segmented scenes contribute to understanding the models&#39; effectiveness in capturing semantic information within 3D environments.</p>
                    <h3 id="metrics-">Metrics:</h3>
                    <ul>
                    <li>Intersection over Union (IoU): Measures overlap between predicted and ground truth segments for each class.</li>
                    <li>Mean IoU (mIoU): Average IoU across all classes, providing a comprehensive evaluation.</li>
                    <li>Precision and recall: Assess the model&#39;s ability to correctly identify true positives and negatives.</li>
                    </ul>
                    <h2 id="our-approaches">Our Approaches</h2>
                    <h3 id="data-preprocessing">Data Preprocessing</h3>
                    <p>The datasets from ShapeNet and ModelNet are already preprocessed and were made ready for training and testing. However, the DALES dataset is only labeled while the data are still available as raw LAS files. Due to unavailability of pre-written libraries for PCD data, a lot of custom functions and logics are written and implemented for handling point cloud preprocessing.</p>
                    <h3 id="data-cleaning-and-transformation">Data Cleaning and Transformation</h3>
                    <p>Missing values in DALES are replaced using an intuitive KNN classification technique inspired by us. The model was trained with the labeled points, and the non-labeled dirty points are classified based on K Nearest Neighbors. For data normalization, StandardScaler and MinMaxScaler techniques are employed.</p>
                    <h3 id="training-batch-preparation">Training Batch Preparation</h3>
                    <p>A custom cross-validation technique has been employed by us to split the larger dataset into chunks. (A chunk refers to a spatially organized subset of PCD that allows for more efficient processing and handling of large datasets). Each chunk is sliced from the 3D PCD by sorting X and Y coordinates using custom logic and functions and each of them is normalized separately. These chunks were then used as batch-wise data for feeding the model.</p>
                    <h2 id="general-comparison-between-pointnet-and-dg-cnn">General Comparison Between PointNet and DG-CNN</h2>
                    <p>A comparative analysis between PointNet and DGCNN involves evaluating their performance metrics on object classification tasks, discussing their strengths and weaknesses, computational efficiency, and generalizability. Highlighting the advantages and limitations of each model in terms of handling point cloud data for object classification purposes aids in understanding their suitability for different applications and datasets.</p>
                    <h3 id="strengths-of-pointnet-">Strengths of PointNet:</h3>
                    <ul>
                    <li>Simpler architecture, faster training and inference</li>
                    <li>Effective for global feature extraction</li>
                    <li>Well-suited for large-scale point clouds</li>
                    </ul>
                    <h3 id="strengths-of-dgcnn-">Strengths of DGCNN:</h3>
                    <ul>
                    <li>Superior capture of local geometric structures</li>
                    <li>More robust to noise and occlusion</li>
                    <li>Often achieves higher accuracy on complex datasets</li>
                    </ul>
                    <h3 id="computational-efficiency-">Computational Efficiency:</h3>
                    <ul>
                    <li>PointNet generally faster than DGCNN</li>
                    <li>Trade-off between accuracy and speed to consider</li>
                    </ul>
                    <h3 id="generalizability-">Generalizability:</h3>
                    <ul>
                    <li>DGCNN may generalize better to unseen data due to local feature focus</li>
                    <li>PointNet&#39;s global features might be less adaptable</li>
                    </ul>
                    <h3 id="accuracy-comparison-">Accuracy Comparison:</h3>
                    <ul>
                    <li>Choice of model depends on dataset complexity and task requirements</li>
                    <li>DGCNN often favored for datasets with fine-grained details and noise</li>
                    <li>PointNet suitable for large-scale datasets where speed is critical</li>
                    </ul>
                    <table>
                    <thead>
                    <tr>
                    <th>Dataset</th>
                    <th>Model</th>
                    <th>Task</th>
                    <th>Train Accuracy</th>
                    <th>Test Accuracy</th>
                    <th>Model IoU</th>
                    <th>Learning Rate</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr>
                    <td>ShapeNet</td>
                    <td>PointNet</td>
                    <td>Classification</td>
                    <td>90-95%</td>
                    <td>85-90%</td>
                    <td>-</td>
                    <td>0.001-0.01</td>
                    </tr>
                    <tr>
                    <td>ModelNet</td>
                    <td>DG-CNN</td>
                    <td>Part</td>
                    <td>92.1-95.2%</td>
                    <td>95-98.9%</td>
                    <td>97.5%</td>
                    <td>0.001</td>
                    </tr>
                    <tr>
                    <td>ModelNet</td>
                    <td>PointNet</td>
                    <td>Part Segmentation</td>
                    <td>92-96%</td>
                    <td>87-90%</td>
                    <td>-</td>
                    <td>0.001-0.01</td>
                    </tr>
                    <tr>
                    <td>Dales Dataset</td>
                    <td>PointNet</td>
                    <td>Semantic Segmentation</td>
                    <td>85-88%</td>
                    <td>84-87.8%</td>
                    <td>-</td>
                    <td>0.001-0.01</td>
                    </tr>
                    </tbody>
                    </table>
                    <h2 id="architecture-comparison-and-complexity-analysis">Architecture - Comparison and Complexity Analysis</h2>
                    <h3 id="pointnet-">PointNet:</h3>
                    <p><img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/070bd0c1-f650-41c5-8b70-181479649a82" alt="image"></p>
                    <h4 id="shared-mlp-multi-layer-perceptron-">Shared MLP (Multi-Layer Perceptron):</h4>
                    <p>Functionality:</p>
                    <ul>
                    <li>PointNet processes each point independently through a shared MLP.</li>
                    <li>The shared MLP captures local features for each point.</li>
                    </ul>
                    <h4 id="max-pooling-">Max Pooling:</h4>
                    <p>Functionality:</p>
                    <ul>
                    <li>Global information aggregation is achieved through max pooling.</li>
                    <li>Max pooling provides permutation invariance, making PointNet robust to different point orders.</li>
                    </ul>
                    <h4 id="symmetric-function-">Symmetric Function:</h4>
                    <p>Functionality:</p>
                    <ul>
                    <li>The max pooling operation acts as a symmetric function, ensuring the network&#39;s permutation invariance.</li>
                    <li>Symmetric functions enable PointNet to operate on unordered point sets.</li>
                    </ul>
                    <h3 id="dgcnn-">DGCNN:</h3>
                    <p><img src="https://github.com/MirshaMorningstar/3D-Point-Cloud-processing-/assets/84216040/3fc357cd-adfb-4386-b84f-d6939f8e6a6a" alt="image"></p>
                    <h4 id="edgeconv-edge-convolution-">EdgeConv (Edge Convolution):</h4>
                    <p>Functionality:</p>
                    <ul>
                    <li>DGCNN introduces EdgeConv layers to capture local geometric features based on the edges between points.</li>
                    <li>The dynamic graph construction adapts to the local structure of the point cloud.</li>
                    </ul>
                    <h4 id="dynamic-graph-construction-">Dynamic Graph Construction:</h4>
                    <p>Functionality:</p>
                    <ul>
                    <li>DGCNN constructs a dynamic graph based on nearest neighbors or other heuristics.</li>
                    <li>The dynamic graph allows the network to adapt to variations in point distribution and local structures.</li>
                    </ul>
                    <h4 id="graph-pooling-">Graph Pooling:</h4>
                    <p>Functionality:</p>
                    <ul>
                    <li>DGCNN uses graph pooling to aggregate information from local neighborhoods.</li>
                    <li>Graph pooling enables the network to capture hierarchical features and maintain a global perspective.</li>
                    </ul>
                    <h2 id="comparative-study-of-pointnet-and-dgcnn-performance">Comparative Study of PointNet and DGCNN Performance</h2>
                    <p>The comparative study between PointNet and DGCNN involves a comprehensive analysis of their performance across various tasks such as object classification, part segmentation, and semantic segmentation. Metrics like accuracy, IoU, precision, and recall are evaluated for both models across different datasets. Discussing their performance on specific challenges and datasets aids in understanding their relative strengths and weaknesses.</p>
                    <ul>
                    <li><p><strong>Object classification</strong>: DGCNN generally outperforms PointNet in terms of accuracy and F1-score, particularly on complex datasets with fine-grained details. However, PointNet&#39;s simpler architecture offers faster training and inference, making it</p>
                    <p>suitable for large-scale datasets where speed is crucial.</p>
                    </li>
                    <li><strong>Part segmentation</strong>: Similar trends emerge here, with DGCNN achieving higher mIoU scores due to its superior capture of local geometric features. Nonetheless, PointNet can be faster and more efficient for large point clouds.</li>
                    <li><strong>Semantic segmentation</strong>: On LiDAR data, DGCNN is expected to excel due to its ability to handle fine-grained details and noise present in aerial scans. However, PointNet&#39;s efficiency might be advantageous for large-scale urban scenes.</li>
                    </ul>
                    <p>Considerations:</p>
                    <ul>
                    <li><strong>Computational efficiency</strong>: PointNet is generally faster than DGCNN.</li>
                    <li><strong>Generalizability</strong>: DGCNN may generalize better to unseen object instances.</li>
                    <li><strong>Data characteristics</strong>: Choice of model depends on dataset complexity and the importance of local features.</li>
                    </ul>
                    <h2 id="conclusion">Conclusion</h2>
                    <p>The exploration of PointNet and DGCNN for processing point cloud data has revealed their effectiveness in various tasks within 3D data analysis. PointNet demonstrates proficiency in handling unordered point sets for object classification and part segmentation, while DGCNN leverages graph-based convolutions for tasks like semantic segmentation. Both models exhibit strengths in capturing local and global features within point clouds.</p>
                    <h2 id="citations">Citations</h2>
                    <p>[1] C. Qi et al, “PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation”, 2017<br>[2] W. Yang et al, “Dynamic Graph CNN for Learning on Point Clouds”, 2018</p>




                </div>
            </div>
        </div>
    </div>

    <!-- Skills Section -->
    <section id="skills" class="bg-light py-5">
        <div class="container-fluid">
            <h2 class="text-center mb-4">Skills</h2>
            <div class="skills-container">
                <div class="skills-wrapper">
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Programming Languages and Database Management</h5>
                            <p class="card-text">Python, Mongo DB, C, C++, R, M, SQL, Power Query, DAX</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Data Visualization and Exploration</h5>
                            <p class="card-text">Pandas, NumPy, Matplotlib, Seaborn, Plotly, Excel, Power-BI, Streamlit, QGIS</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Machine Learning</h5>
                            <p class="card-text">Predictive Modeling, Classification, Regression, Feature Engineering, Dimensionality Reduction</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">MLOps Frameworks</h5>
                            <p class="card-text">Weights and Biases, MLFlow, Power-BI, BentoML, Streamlit</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Deep Learning</h5>
                            <p class="card-text">Computer Vision, Deep Learning Techniques, ANN, RNN - LSTM, GRU, Autoencoders</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Web Development and Deployment</h5>
                            <p class="card-text">HTML, CSS, React, Javascript, TypeScript, Bootstrap, Supabase, Pythonanywhere, Github, Github Pages</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">AI & NLP Frameworks</h5>
                            <p class="card-text">ChatGPT, Gemini, Deepseek</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Design and Development</h5>
                            <p class="card-text">Figma, Canva, MS Tools (AI), Google Docs/Sheets/Slides (AI)</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Collaboration and Communication</h5>
                            <p class="card-text">Cross-Functional Team Collaboration, Strategic Analysis, Problem Solving</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Programming Languages and Database Management</h5>
                            <p class="card-text">Python, Mongo DB, C, C++, R, M, SQL, Power Query, DAX</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Data Visualization and Exploration</h5>
                            <p class="card-text">Pandas, NumPy, Matplotlib, Seaborn, Plotly, Excel, Power-BI, Streamlit, QGIS</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Machine Learning</h5>
                            <p class="card-text">Predictive Modeling, Classification, Regression, Feature Engineering, Dimensionality Reduction</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">MLOps Frameworks</h5>
                            <p class="card-text">Weights and Biases, MLFlow, Power-BI, BentoML, Streamlit</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Deep Learning</h5>
                            <p class="card-text">Computer Vision, Deep Learning Techniques, ANN, RNN - LSTM, GRU, Autoencoders</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Web Development and Deployment</h5>
                            <p class="card-text">HTML, CSS, React, Javascript, TypeScript, Bootstrap, Supabase, Pythonanywhere, Github, Github Pages</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">AI & NLP Frameworks</h5>
                            <p class="card-text">ChatGPT, Gemini, Deepseek</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Design and Development</h5>
                            <p class="card-text">Figma, Canva, MS Tools (AI), Google Docs/Sheets/Slides (AI)</p>
                        </div>
                    </div>
                    <div class="card override_card">
                        <div class="card-body">
                            <h5 class="card-title">Collaboration and Communication</h5>
                            <p class="card-text">Cross-Functional Team Collaboration, Strategic Analysis, Problem Solving</p>
                        </div>
                    </div>

                </div>
            </div>
        </div>
    </section>


    <!-- Certifications Section -->
    <section id="certifications" class="bg-dark py-6">
        <div class="container">
            <h2 class="text-center mb-4">Certificates</h2>
            <div class="row d-flex align-items-center justify-content-center">
                <!-- Left Column (2 Cards) -->
                <div class="col-md-8">
                    <!-- Certification Card 1 -->
                    <div class="card mb-4 certificate-card" data-toggle="modal" data-target="#certification1Modal">
                        <div class="card-body">
                            <h5 class="card-title">PL-300 Certification: Microsoft Power BI Data Analyst</h5>
                            <p class="card-text">This certification validates expertise in using Microsoft Power BI to analyze data, create interactive reports, and derive business insights. It covers data preparation, modeling, visualization, and deployment of Power BI solutions. (click to expand)</p>
                        </div>
                    </div>

                    <!-- Certification Card 2 -->
                    <div class="card mb-4 certificate-card" data-toggle="modal" data-target="#certification2Modal">
                        <div class="card-body">
                            <h5 class="card-title">IIT Bombay FOSSEE Mapathon 2023 - Certificate of Championship</h5>
                            <p class="card-text">Champion (International Rank - 5) in AI-Powered Thematic Maps Creation.</p>
                            <p class="card-text">This certificate is awarded to participants who excelled in the IIT Bombay FOSSEE Mapathon, a geospatial mapping competition. It recognizes proficiency in GIS, cartography, and open-source mapping tools. (click to expand)</p>
                        </div>
                    </div>
                </div>

                <!-- Right Column (1 Card) -->
                <div class="col-md-4 d-flex align-items-center">
                    <div class="card mb-4 certificate-card" data-toggle="modal" data-target="#certification3Modal">
                        <div class="card-body">
                            <h5 class="card-title">AU- TVS Quality Quest 2023 Paper Presentation Winner</h5>
                            <p class="card-text">This certificate is a testament to the fact that My Idea and thesis proposed on Cybernated Road Network Management in the 24th Annual Conference on Quality Management was recognised and given 3rd prize for the Paper Presentation.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Certification Modals -->
    <!-- Modal for Certification 1 -->
    <div class="modal fade" id="certification1Modal" tabindex="-1" aria-labelledby="certification1ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="certification1ModalLabel">Microsoft Power BI Data Analyst (PL-300)</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Description:</strong> This certification validates expertise in using Power BI for data analysis, including data modeling, visualization, and report creation.</p>
                    <p><strong>Skills Covered:</strong></p>
                    <ul>
                        <li><strong>Skill 1: Data Preparation</strong> - Cleaned, transformed, and loaded data from various sources using Power Query and DAX.</li>
                        <li><strong>Skill 2: Data Modeling</strong> - Designed and optimized data models with relationships, hierarchies, and calculated measures for performance efficiency.</li>
                        <li><strong>Skill 3: Data Visualization & Reporting</strong> - Built interactive dashboards and reports with advanced visual elements to communicate insights effectively.</li>
                        <li><strong>Skill 4: Deployment & Security</strong> - Published and managed Power BI reports in the cloud, ensuring role-based security and data governance.</li>
                    </ul>
                    <p><strong>Certificate Link:</strong> <a href="https://github.com/MirshaMorningstar/Personal-Certificates/blob/main/POWER%20BI%20COURSE%20COMPLETION.pdf" target="_blank">View Certificate</a></p>
                    <p><strong>Certificate PDF:</strong></p>
                    <img src="assets/POWER BI COURSE COMPLETION_page-0001.jpg" alt="Certificate 1 Photo">
                    
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Modal for Certification 2 -->
    <div class="modal fade" id="certification2Modal" tabindex="-1" aria-labelledby="certification2ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="certification2ModalLabel">IIT Bombay FOSSEE Mapathon 2023 - Certificate of Championship</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Description:</strong> Led a transformative project on AI-Powered Illustrious Thematic Maps creation, utilized Advanced Data Science, Analytics, and Visual Representation Techniques to enhance the infrastructure and quality of life in the Nilgiris region.</p>
                    <p><strong>Champion (AIR - 5) in AI-Powered Thematic Maps Creation using QGIS framework.</strong></p>
                    <p><strong>Skills Covered:</strong></p>
                    <ul>
                        <li><strong>Skill 1: Geospatial Data Collection</strong> - Conducted extensive geospatial data collection using advanced tools and techniques.</li>
                        <li><strong>Skill 2: AIoT Modeling</strong> - Developed AI-powered IoT models to analyze and predict regional infrastructure needs.</li>
                        <li><strong>Skill 3: Data Visualization</strong> - Created highly accurate and visually appealing thematic maps using tools like QGIS and Plotly.</li>
                    </ul>
                    <p><strong>Certificate Link:</strong> <a href="https://github.com/MirshaMorningstar/IIT-Bombay---Fossee-Mapathon-2023-Championship-ProjectWork/blob/main/Decarta/Certificate%20of%20Appreciation.pdf" target="_blank">View Certificate</a></p>
                    <p><strong>Certificate PDF:</strong></p>
                    <img src="assets/Certificate of Appreciation_page-0001.jpg" alt="Certificate 2 Photo">
                            
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Modal for Certification 3 -->
    <div class="modal fade" id="certification3Modal" tabindex="-1" aria-labelledby="certification3ModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-lg">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="certification3ModalLabel">AU- TVS Quality Quest 2023 Paper Presentation Winner</h5>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                        <span aria-hidden="true">&times;</span>
                    </button>
                </div>
                <div class="modal-body">
                    <p><strong>Description:</strong> Presented a research paper on Cybernated Road Network Management (CRNM) at AU TVS Q'QUEST 2023, focusing on AI-driven traffic optimization, smart infrastructure, and real-time road safety enhancements. The study introduced innovative solutions for reducing congestion, improving traffic flow, and integrating IoT with road management systems. This certificate is a testament to the fact that My Idea and thesis proposed on the 24th Annual Conference on Quality Management was recognised and given 3rd prize for the Paper Presentation.</p>
                    <p><strong>Skills Covered:</strong></p>
                    <ul>
                        <li><strong>Skill 1: Intelligent Traffic Management</strong> - Designed AI-powered models to predict and optimize traffic flow, reducing congestion and improving urban mobility.</li>
                        <li><strong>Skill 2: IoT & Smart Infrastructure</strong> - Integrated IoT-enabled sensors and automated road systems to enhance real-time monitoring and decision-making.</li>
                        <li><strong>Skill 3: Data-Driven Road Safety</strong> - Developed predictive analytics models to identify accident-prone areas and propose safety measures.</li>
                        <li><strong>Skill 4: Research & Technical Documentation</strong> - Conducted literature reviews, structured findings into a well-documented research paper, and formulated data-backed conclusions.</li>
                        <li><strong>Skill 5: Presentation & Public Speaking</strong> - Delivered a professional research presentation, effectively communicating complex concepts to an academic and industry audience.</li>
                    </ul>
                    <p><strong>Certificate Link:</strong> <a href="https://github.com/MirshaMorningstar/CRNM-Paper-Presentation/blob/master/Certificate%20AU%20TVS%20Q'QUEST%202023.jpg" target="_blank">View Certificate</a></p>
                    <p><strong>Certificate PDF:</strong></p>
                    <img src="assets/Certificate AU TVS Q'QUEST 2023.jpg" alt="Certificate 1 Photo">
                    
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Education Section -->
    <section id="education" class="bg-light py-5">
        <div class="container">
            <h2 class="text-center mb-4">Education</h2>
            <div class="row d-flex align-items-center justify-content-center">
                <div class="col-md-6">
                    <div class="card mb-4 override_card">
                        <div class="card-body">
                            <h5 class="card-title">B.Tech - Artificial Intelligence and Data Science</h5>
                            <p class="card-text">Anna University, Madras Institute of Technology Campus</p>
                            <p class="card-text">( Major in Artificial Intelligence, Full Stack Data Science
                                and Intermediate Machine Learning Operations. )</p>
                            <p class="card-text">2022 - 2026 (Pursuing)</p>
                            <p class="card-text">CGPA: 8.7</p>
                        </div>
                    </div>
                </div>
                <div class="col-md-6 d-flex flex-column justify-content-center">
                    <div class="card mb-3 override_card">
                        <div class="card-body">
                            <h5 class="card-title">12th HSC Exam</h5>
                            <p class="card-text">98% (588/600)</p>
                        </div>
                    </div>
                    <div class="card mb-3 override_card">
                        <div class="card-body">
                            <h5 class="card-title">10th SSLC Exam</h5>
                            <p class="card-text">93% (466/500)</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Reports Published Section -->
    <section id="reports" class=" bg-dark py-6">
        <div class="container">
            <h2 class="text-center mb-4">Reports Published</h2>
            <div class="row">
                <!-- Report 1 -->
                <div class="col-md-6 mb-4">
                    <div class="card h-100 report-card">
                        <div class="card-body">
                            <h5 class="card-title">Dynamic Graph Convolutional Neural Network on ShapeNet's Airplane Class</h5>
                            <p class="card-text">This report explores the application of Dynamic Graph Convolutional Neural Networks (DGCNNs) on the Airplane class of the ShapeNet dataset. It highlights the model's ability to capture complex geometric structures and improve 3D shape classification accuracy.</p>
                            <a href="https://api.wandb.ai/links/team-dubakur/czgvdkmv" class="btn btn-primary" target="_blank" >Read Report</a>
                        </div>
                    </div>
                </div>

                <!-- Report 2 -->
                <div class="col-md-6 mb-4">
                    <div class="card h-100 report-card">
                        <div class="card-body">
                            <h5 class="card-title">Dynamic Graph Convolutional Neural Network on ShapeNet's Cars Class</h5>
                            <p class="card-text">This report investigates the performance of Dynamic Graph Convolutional Neural Networks (DGCNNs) on the Cars class of the ShapeNet dataset. It demonstrates how DGCNNs can effectively model intricate shapes and improve object recognition in 3D datasets.</p>
                            <a href="https://api.wandb.ai/links/team-dubakur/pnlpveqe" class="btn btn-primary" target="_blank">Read Report</a>
                        </div>
                    </div>
                </div>

                <!-- Report 3 -->
                <div class="col-md-6 mb-4">
                    <div class="card h-100 report-card">
                        <div class="card-body">
                            <h5 class="card-title">Dynamic Graph Convolutional Neural Network on ShapeNet's Chairs Class</h5>
                            <p class="card-text">This report evaluates the effectiveness of Dynamic Graph Convolutional Neural Networks (DGCNNs) on the Chairs class of the ShapeNet dataset. It showcases the model's capability to handle diverse and complex 3D shapes, achieving state-of-the-art results in shape classification.</p>
                            <a href="https://api.wandb.ai/links/team-dubakur/wvvugnbq" class="btn btn-primary" target="_blank">Read Report</a>
                        </div>
                    </div>
                </div>

                <!-- Report 4 -->
                <div class="col-md-6 mb-4">
                    <div class="card h-100 report-card">
                        <div class="card-body">
                            <h5 class="card-title">Cybernated Road Network Management (AIoT)</h5>
                            <p class="card-text">This report presents a comprehensive analysis of Cybernated Road Network Management (CRNM) using AI and IoT technologies. It proposes innovative solutions for optimizing road networks, reducing accidents, and improving traffic management through data-driven approaches.</p>
                            <a href="https://github.com/MirshaMorningstar/CRNM-Paper-Presentation/blob/master/CRNM%20Part2.pdf" class="btn btn-primary" target="_blank">Read Report</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Internship Section -->
    <section id="internship" class="bg-light py-5">
        <div class="container">
            <h2 class="text-center mb-4">Internship Experience</h2>
            <div class="row">
                <div class="col-md-12">
                    <div class="card mb-4 internship-card" data-toggle="modal" data-target="#harpyAerospaceModal">
                        <div class="card-body">
                            <h5 class="card-title">Artificial Intelligence and Machine Learning Intern</h5>
                            <p class="card-text">Harpy Aerospace Private Limited, India</p>
                            <p class="card-text">June 2024 - July 2024</p>
                        </div>
                    </div>
                </div>
                <!-- Modal for Harpy Aerospace Internship -->
                <div class="modal fade" id="harpyAerospaceModal" tabindex="-1" aria-labelledby="harpyAerospaceModalLabel" aria-hidden="true">
                    <div class="modal-dialog modal-lg">
                        <div class="modal-content">
                            <div class="modal-header">
                                <h5 class="modal-title" id="harpyAerospaceModalLabel">Artificial Intelligence and Machine Learning Intern</h5>
                                <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                                    <span aria-hidden="true">&times;</span>
                                </button>
                            </div>
                            <div class="modal-body">
                                <p><strong>Company:</strong> Harpy Aerospace Private Limited, India</p>
                                <p><strong>Duration:</strong> Feb 2023 - June 2023</p>
                                <p><strong>Role:</strong> Artificial Intelligence and Machine Learning Intern</p>
                                <p><strong>Responsibilities:</strong></p>
                                <ul>
                                    <li>Developed predictive models for aircraft maintenance using machine learning algorithms.</li>
                                    <li>Preprocessed and analyzed large datasets to identify patterns and trends.</li>
                                    <li>Collaborated with the engineering team to integrate AI models into real-time systems.</li>
                                    <li>Created interactive dashboards to visualize model performance and insights.</li>
                                </ul>
                                <p><strong>Skills Gained:</strong></p>
                                <ul>
                                    <li>Machine Learning (Python, Scikit-learn, TensorFlow)</li>
                                    <li>Data Analysis and Visualization (Pandas, Matplotlib, Seaborn)</li>
                                    <li>Model Deployment (Flask, Streamlit)</li>
                                    <li>Team Collaboration and Agile Project Management</li>
                                </ul>
                                <img src="assets/Summer Internship - Harpy Aerospace Private Limited, India.png" alt="Certificate Photo">
                            </div>
                            <div class="modal-footer">
                                <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="bg-dark py-6">
        <div class="container-fluid">
            <h2 class="text-center mb-4">Contact</h2>
            <div class="row">
                <div class="col-md-6 mx-auto">
                    <!-- Form with Formspree Integration -->
                    <form id="contact-form" action="https://formspree.io/f/meoajbbr" method="POST">
                        <div class="form-group">
                            <input type="text" name="name" class="form-control" placeholder="Your Name" required>
                        </div>
                        <div class="form-group">
                            <input type="email" name="email" class="form-control" placeholder="Your Email" required>
                        </div>
                        <div class="form-group">
                            <textarea name="message" class="form-control" rows="5" placeholder="Your Message" required></textarea>
                        </div>
                        <button type="submit" class="btn btn-primary btn-block">Send Message</button>
                    </form>
                    <p id="success-message" class=" text-center mt-3" style="display: none; color:#006aff">
                        Thank you! Your message just landed in my inbox. I’ll respond as soon as possible!
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="text-white text-center py-3" style = "color:#006aff">
        <div class="container">
            <p>&copy; 2025 Mirsha A.K. All rights reserved.</p>
            <p>
                <a href="https://www.linkedin.com/in/mirshamorningstar" class="text-white mr-3"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/mirshamorningstar" class="text-white mr-3"><i class="fab fa-github"></i></a>
                <a href="mailto:a.k.mirsha9@gmail.com" class="text-white"><i class="fas fa-envelope"></i></a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap JS and dependencies -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>

    <script>
        document.addEventListener("DOMContentLoaded", function () {
            document.getElementById("contact-form").addEventListener("submit", function (event) {
                event.preventDefault(); // Prevent default form submission
    
                let form = this;
                let formData = new FormData(form);
    
                fetch(form.action, {
                    method: form.method,
                    body: formData,
                    headers: { "Accept": "application/json" }
                })
                .then(response => response.json())
                .then(data => {
                    if (data.ok) {
                        form.reset(); // Clear the form
                        let successMessage = document.getElementById("success-message");
                        successMessage.style.display = "block"; // Show success message
                        setTimeout(() => {
                            successMessage.style.display = "none";
                        }, 5000); // Hide success message after 3 seconds
                    } else {
                        alert("Oops! Something went wrong. Please try again.");
                    }
                })
                .catch(error => {
                    alert("Oops! Something went wrong. Please try again.");
                });
            });
        });
    </script>

    <script>

        document.addEventListener("DOMContentLoaded", function () {
            const sections = document.querySelectorAll("section"); // All sections
            const navLinks = document.querySelectorAll(".nav-link"); // Navbar links

            function updateNavbar() {
                let scrollPosition = window.scrollY + 150; // Adjust to detect sections early

                sections.forEach((section, index) => {
                    let sectionTop = section.offsetTop;
                    let sectionBottom = sectionTop + section.offsetHeight;
                    let navItem = navLinks[index];

                    if (scrollPosition >= sectionTop && scrollPosition < sectionBottom) {
                        // Highlight active section
                        navItem.classList.add("active");
                    } else {
                        navItem.classList.remove("active");
                    }

                    // Mark previous sections as completed
                    if (scrollPosition >= sectionBottom) {
                        navItem.classList.add("completed");
                    } else {
                        navItem.classList.remove("completed");
                    }
                });
            }

            window.addEventListener("scroll", updateNavbar);
            updateNavbar(); // Initial call to update on page load
        });


        document.addEventListener('DOMContentLoaded', function () {
        console.log("Smooth scrolling script loaded!");

        // Custom smooth scroll function with 60px top padding
        function smoothScrollTo(target, duration) {
            const targetElement = document.querySelector(target);
            if (!targetElement) return;

            const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - 60; // Adjusted for padding
            const startPosition = window.pageYOffset;
            const distance = targetPosition - startPosition;
            let startTime = null;

            function animation(currentTime) {
                if (startTime === null) startTime = currentTime;
                const timeElapsed = currentTime - startTime;
                const run = easeInOutQuad(timeElapsed, startPosition, distance, duration);
                window.scrollTo(0, run);
                if (timeElapsed < duration) requestAnimationFrame(animation);
            }

            // Easing function for smooth acceleration and deceleration
            function easeInOutQuad(t, b, c, d) {
                t /= d / 2;
                if (t < 1) return c / 2 * t * t + b;
                t--;
                return -c / 2 * (t * (t - 2) - 1) + b;
            }

            requestAnimationFrame(animation);
        }

        document.addEventListener("DOMContentLoaded", function () {
            const wrapper = document.querySelector(".skills-wrapper");

            let scrollAmount = 0;
            const scrollSpeed = 5; // Adjust speed (lower = slower)

            function autoScroll() {
                scrollAmount += scrollSpeed;
                wrapper.style.transform = `translateX(-${scrollAmount}px)`;

                // Reset scroll position when half of the duplicated items have scrolled
                if (scrollAmount >= wrapper.scrollWidth / 2) {
                    scrollAmount = 0;
                    wrapper.style.transform = "translateX(0)"; // Prevent flickering
                }

                requestAnimationFrame(autoScroll);
            }

            autoScroll();
        });


        // Add click event listeners to all anchor links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const targetId = this.getAttribute('href');
                console.log("Clicked link with href:", targetId);

                const targetElement = document.querySelector(targetId);
                if (targetElement) {
                    console.log("Target element found:", targetElement);
                    smoothScrollTo(targetId, 1000); // Adjust duration (in milliseconds) to control speed
                } else {
                    console.log("Target element not found!");
                }
            });
        });

        
        
    });

    
    </script>
    
</body>
</html>
